{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "train_batchsz, val_batchsz = 8, 8\n",
    "epoch = 10\n",
    "lr = 1.5e-3\n",
    "momentum = 0.90\n",
    "numofclass = 7\n",
    "hw1train_path = \"/data/dlcv/hw1/hw1_data/p2_data/train/\"\n",
    "hw1val_path = \"/data/dlcv/hw1/hw1_data/p2_data/validation/\"\n",
    "checkpoint_path = \"/data/allen/hw1model/vgg16fcn32.pth\"\n",
    "log_path = \"/data/allen/hw1model/vgg16fcn32_log.txt\"\n",
    "cls_color = {\n",
    "    0:  [0, 255, 255],\n",
    "    1:  [255, 255, 0],\n",
    "    2:  [255, 0, 255],\n",
    "    3:  [0, 255, 0],\n",
    "    4:  [0, 0, 255],\n",
    "    5:  [255, 255, 255],\n",
    "    6: [0, 0, 0],\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.set_device(7)\n",
    "print('Device used:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGBToClass(mask):\n",
    "    bitmask = (np.array(mask) >= 128).astype(int)\n",
    "    bitmask = 4 * bitmask[0,:,:] + 2 * bitmask[1,:,:] + bitmask[2,:,:]\n",
    "    classmask = np.zeros((mask.shape[1], mask.shape[2]))\n",
    "    classmask[bitmask == 3] = 0\n",
    "    classmask[bitmask == 6] = 1\n",
    "    classmask[bitmask == 5] = 2\n",
    "    classmask[bitmask == 2] = 3\n",
    "    classmask[bitmask == 1] = 4\n",
    "    classmask[bitmask == 7] = 5\n",
    "    classmask[bitmask == 0] = 6\n",
    "    return classmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, dirpath, transform=None):\n",
    "        self.images, self.masks = {}, {}\n",
    "        self.transform = transform\n",
    "        filenames = glob.glob(os.path.join(dirpath, \"*sat.jpg\"))\n",
    "        for filename in filenames:\n",
    "            image_fn = os.path.split(filename)[1]\n",
    "            idx = int(image_fn.split(\"_\")[0])\n",
    "            image = Image.open(filename)\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            self.images[idx] = image\n",
    "        filenames = glob.glob(os.path.join(dirpath, \"*mask.png\"))\n",
    "        for filename in filenames:\n",
    "            image_fn = os.path.split(filename)[1]\n",
    "            idx = int(image_fn.split(\"_\")[0])\n",
    "            mask = Image.open(filename)\n",
    "            if self.transform is not None:\n",
    "                mask = self.transform(mask)\n",
    "            #convert mask pixel to each class\n",
    "            self.masks[idx] = RGBToClass(mask)\n",
    "            # print(mask[:,0,0], self.masks[idx][0,0])\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.masks[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Total number of samples in the dataset \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "val_tfm = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "trainset, valset = Mydataset(hw1train_path, transform=train_tfm), Mydataset(hw1val_path, transform=val_tfm)\n",
    "trainset_loader = DataLoader(trainset, batch_size=train_batchsz, shuffle=True, num_workers=1, pin_memory=True)\n",
    "valset_loader = DataLoader(valset, batch_size=val_batchsz, shuffle=False, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16FCN32(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        vgg16 = torchvision.models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "        # print(vgg16)\n",
    "        self.block1 = nn.Sequential(*list(vgg16.children())[0][0:5])\n",
    "        self.block2 = nn.Sequential(*list(vgg16.children())[0][5:10])\n",
    "        self.block3 = nn.Sequential(*list(vgg16.children())[0][10:17])\n",
    "        self.block4 = nn.Sequential(*list(vgg16.children())[0][17:24])\n",
    "        self.block5 = nn.Sequential(*list(vgg16.children())[0][24:])\n",
    "        self.fcn32 = nn.Sequential(\n",
    "            nn.Conv2d(512, 4096, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(4096, 4096, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(4096, numofclass, kernel_size=1, padding=0),\n",
    "            nn.ConvTranspose2d(numofclass, numofclass, kernel_size=32, stride=32)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x1)\n",
    "        x3 = self.block3(x2)\n",
    "        x4 = self.block4(x3)\n",
    "        x5 = self.block5(x4)\n",
    "        x6 = self.fcn32(x5)\n",
    "        return x6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vgg16FCN32(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fcn32): Sequential(\n",
      "    (0): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Conv2d(4096, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): ConvTranspose2d(7, 7, kernel_size=(32, 32), stride=(32, 32))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "myvgg16fcn32 = Vgg16FCN32().to(device)\n",
    "print(myvgg16fcn32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeIoU(output, label):\n",
    "    mean_iou = 0.\n",
    "    label = label.astype(np.uint8)\n",
    "    outputmasks = output.argmax(axis=1).astype(np.uint8)\n",
    "    # print(\"output:{} -> outmasks:{}\".format(output[0,:,0,0], outputmasks[0,0,0]))\n",
    "    for i in range(6):\n",
    "        tp_fp = np.sum(outputmasks == i)\n",
    "        tp_fn = np.sum(label == i)\n",
    "        tp = np.sum((outputmasks == i) * (label == i))\n",
    "        # print(\"i {} tp_fp : {} tp_fn : {} tp : {}\".format(i, tp_fp, tp_fn, tp))\n",
    "        if (tp_fp + tp_fn - tp) > 0:\n",
    "            iou = tp / (tp_fp + tp_fn - tp)\n",
    "            mean_iou += iou / 6\n",
    "    return mean_iou  \n",
    "    \n",
    "def ClassToRGB(class_img):\n",
    "    class_img = np.array(class_img)\n",
    "    m, n = class_img.shape[0], class_img.shape[1]\n",
    "    rgb = np.empty((m, n, 3), dtype=torch.uint8)\n",
    "    for i in range(numofclass):\n",
    "        rgb[class_img[:,:] == i,:] = cls_color[i] \n",
    "    return rgb                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadbestiou():\n",
    "    best_iou = 0.\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                linelist = line.split(\" \")\n",
    "                if linelist[0] == checkpoint_path:\n",
    "                    best_iou = float(linelist[-1].strip(\"%\"))\n",
    "                    break\n",
    "    return best_iou / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    lrscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,100,150], gamma=0.6)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_iou = loadbestiou()\n",
    "    print(\"best_acc = {:.3%}\".format(best_iou))\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        train_loss, train_iou = 0., 0.\n",
    "        output_list, label_list= [], []\n",
    "        for idx, (img, label) in enumerate(trainset_loader):\n",
    "            img, label = img.to(device, dtype=torch.float32), label.to(device, dtype=torch.long)\n",
    "            output = model(img)\n",
    "            # print(img.shape, label.shape, output.shape)\n",
    "            loss = criterion(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            output_list.append(output.detach().cpu().numpy())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "        lrscheduler.step()\n",
    "        train_loss /= len(trainset_loader.dataset)\n",
    "        train_iou = ComputeIoU(np.concatenate(output_list, axis=0), np.concatenate(label_list, axis=0))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_iou = 0., 0.\n",
    "        output_list, label_list= [], []\n",
    "        with torch.no_grad():\n",
    "            for idx, (img, label) in enumerate(valset_loader):\n",
    "                img, label = img.to(device, dtype=torch.float32), label.to(device, dtype=torch.long)\n",
    "                output = model(img)\n",
    "                loss = criterion(output, label)\n",
    "                val_loss += loss.item()\n",
    "                output_list.append(output.detach().cpu().numpy())\n",
    "                label_list.append(label.detach().cpu().numpy())\n",
    "            val_loss /= len(valset_loader.dataset)\n",
    "            val_iou = ComputeIoU(np.concatenate(output_list, axis=0), np.concatenate(label_list, axis=0))\n",
    "        print(\"Epoch {} train loss = {:.6f}, train iou = {:.6f}, valid loss = {:.6f}, valid iou = {:.6f}\".format(ep + 1, train_loss, train_iou, val_loss, val_iou))\n",
    "        if val_iou > best_iou:\n",
    "            save_checkpoint(checkpoint_path, model, optimizer)\n",
    "            with open(log_path, \"w\") as f:    \n",
    "                f.write(\"{} : {:.3%}\".format(checkpoint_path, val_iou))\n",
    "            best_iou = val_iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_acc = 66.920%\n",
      "Epoch 1 train loss = 0.046844, train iou = 0.688354, valid loss = 0.058085, valid iou = 0.623269\n",
      "Epoch 2 train loss = 0.038353, train iou = 0.726641, valid loss = 0.067222, valid iou = 0.613099\n",
      "Epoch 3 train loss = 0.043057, train iou = 0.705388, valid loss = 0.055733, valid iou = 0.650060\n",
      "Epoch 4 train loss = 0.039594, train iou = 0.717801, valid loss = 0.052827, valid iou = 0.657412\n",
      "Epoch 5 train loss = 0.035808, train iou = 0.743944, valid loss = 0.066189, valid iou = 0.607433\n",
      "Epoch 6 train loss = 0.040770, train iou = 0.715237, valid loss = 0.055102, valid iou = 0.646076\n",
      "Epoch 7 train loss = 0.031935, train iou = 0.766838, valid loss = 0.054128, valid iou = 0.665972\n"
     ]
    }
   ],
   "source": [
    "myvgg16fcn32 = Vgg16FCN32().to(device)\n",
    "optimizer = optim.SGD(myvgg16fcn32.parameters(), lr=0.001, momentum=0.9)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "myvgg16fcn32.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(myvgg16fcn32, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
