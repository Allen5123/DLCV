{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"train_batchsz\" : 64,\n",
    "    \"epoch\" : 500,\n",
    "    \"lr\" : 2.0e-4,\n",
    "    \"betas\" : (0., 0.999),\n",
    "    \"train_path\" : '/data/dlcv/hw2/hw2_data/face/train/',\n",
    "    \"device\" :  \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"c_noise\" : 100,\n",
    "    \"feature_dim\" : 64,\n",
    "    \"n_critic\" : 5\n",
    "}\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.set_device(2)\n",
    "print('Device used :', config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # Python built-in random module\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, dirpath, transform = None) -> None:\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        files = glob.glob(os.path.join(dirpath, \"*.png\"))\n",
    "        for file in files:\n",
    "            image = Image.open(file)\n",
    "            self.data.append(image)\n",
    "        self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, c_noise, feature_dim, c_img) -> None:\n",
    "        super().__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.ConvTranspose2d(c_noise, feature_dim*16, kernel_size=4, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_dim*16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            self.dconv_bn_relu(feature_dim*16, feature_dim*8),\n",
    "            self.dconv_bn_relu(feature_dim*8, feature_dim*4),\n",
    "            self.dconv_bn_relu(feature_dim*4, feature_dim*2)\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(feature_dim*2, c_img, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def dconv_bn_relu(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_dim, out_dim, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.project(x)\n",
    "        x2 = self.conv(x1)\n",
    "        return self.last(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_dim, c_img) -> None:\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(c_img, feature_dim, kernel_size=4, stride=2, padding=1, bias=False)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self.conv_bn_lrelu(feature_dim, feature_dim*2, feature_dim//4, feature_dim//4),\n",
    "            self.conv_bn_lrelu(feature_dim*2, feature_dim*4, feature_dim//8, feature_dim//8),\n",
    "            self.conv_bn_lrelu(feature_dim*4, feature_dim*8, feature_dim//16, feature_dim//16),\n",
    "            nn.utils.spectral_norm(nn.Conv2d(feature_dim*8, 1, kernel_size=4, bias=False)),\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def conv_bn_lrelu(self, in_dim, out_dim, h, w):\n",
    "        return nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Conv2d(in_dim, out_dim, kernel_size=4, stride=2, padding=1, bias=False)),\n",
    "            nn.LayerNorm([out_dim, h, w]),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGan():\n",
    "    def __init__(self, config, gpth=None, dpth=None) -> None:\n",
    "        self.config = config\n",
    "        self.G = Generator(self.config[\"c_noise\"], self.config[\"feature_dim\"], 3).to(self.config[\"device\"])\n",
    "        self.D = Discriminator(self.config[\"feature_dim\"], 3).to(self.config[\"device\"])\n",
    "\n",
    "        self.optimizer_G = optim.Adam(self.G.parameters(), lr=self.config[\"lr\"], betas=self.config[\"betas\"])\n",
    "        self.optimizer_D = optim.Adam(self.D.parameters(), lr=self.config[\"lr\"], betas=self.config[\"betas\"])\n",
    "\n",
    "        self.z_samples = torch.randn(32, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #fix sample used\n",
    "\n",
    "        if gpth != None:\n",
    "            if os.path.exists(gpth):\n",
    "                gcheckpoint = torch.load(gpth, map_location=self.config[\"device\"])\n",
    "                self.G.load_state_dict(gcheckpoint[\"model_state_dict\"])\n",
    "                self.optimizer_G.load_state_dict(gcheckpoint[\"optimizer_state_dict\"])\n",
    "            else:\n",
    "                print(\"path error {}\".format(gpth))\n",
    "        if dpth != None:\n",
    "            if os.path.exists(dpth):\n",
    "                dcheckpoint = torch.load(dpth, map_location=self.config[\"device\"])\n",
    "                self.D.load_state_dict(dcheckpoint[\"model_state_dict\"])\n",
    "                self.optimizer_D.load_state_dict(dcheckpoint[\"optimizer_state_dict\"])\n",
    "            else:\n",
    "                print(\"path error {}\".format(dpth))\n",
    "        \n",
    "    def CreateLoader(self):\n",
    "        self.train_loader = DataLoader(FaceDataset(dirpath=self.config[\"train_path\"], transform=train_tfm), batch_size=self.config[\"train_batchsz\"], shuffle=True, pin_memory=True)\n",
    "        self.refresh = len(self.train_loader.dataset) / self.config[\"train_batchsz\"]\n",
    "        print(len(self.train_loader.dataset))\n",
    "\n",
    "    def SaveEpochResult(self, ep):\n",
    "        self.G.eval()\n",
    "        imgs = self.G(self.z_samples).detach().cpu()\n",
    "        imgs = (imgs + 1.) / 2.0\n",
    "        torchvision.utils.save_image(imgs, fp=\"/data/allen/gangrid/sngangp_ep{}.png\".format(ep + 1), padding=0)\n",
    "\n",
    "    def gp(self, real, fake):\n",
    "        lambda_ = 10.\n",
    "        bsz = real.shape[0]\n",
    "        epsilon = torch.rand((bsz, 1, 1, 1), device=self.config[\"device\"])\n",
    "        xhat = (epsilon * real + (1 - epsilon) * fake).requires_grad_(True).to(config[\"device\"])\n",
    "        xhat_logit = self.D(xhat)\n",
    "        gradxhat = torch.autograd.grad(outputs=xhat_logit, inputs=xhat, grad_outputs=torch.ones_like(xhat_logit, device=self.config[\"device\"]),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradxhat = gradxhat.view(bsz, -1)\n",
    "        return lambda_*((gradxhat.norm(2, dim=1)-1)**2).mean()\n",
    "\n",
    "    def train(self):\n",
    "        self.CreateLoader()\n",
    "        for ep in range(self.config[\"epoch\"]):\n",
    "            self.D.train()\n",
    "            self.G.train()\n",
    "            total_loss_D, total_loss_G = 0., 0.\n",
    "            for (idx, real_img) in enumerate(self.train_loader):\n",
    "                bsz = real_img.shape[0]\n",
    "                #train Discriminator\n",
    "                real_img = real_img.to(self.config[\"device\"]) #(bsz, 3, 64, 64)\n",
    "                real_logit = self.D(real_img) #(bsz, )\n",
    "                random_z = torch.randn(bsz, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #(bsz, 100, 1, 1)\n",
    "                fake_img = self.G(random_z) #(bsz, 3, 64, 64)\n",
    "                fake_logit = self.D(fake_img) #(bsz, )\n",
    "                loss_D = -torch.mean(real_logit) + torch.mean(fake_logit) + self.gp(real_img, fake_img)\n",
    "                total_loss_D += loss_D.item()\n",
    "                # Discriminator backwarding\n",
    "                self.D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.optimizer_D.step()\n",
    "                \n",
    "                #train Generater\n",
    "                if (idx + 1) % self.config[\"n_critic\"] == 0:\n",
    "                    random_z = torch.randn(bsz, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #(bsz, 100, 1, 1)\n",
    "                    fake_img = self.G(random_z)  #(bsz, 3, 64, 64)\n",
    "                    fake_logit = self.D(fake_img) #(bsz, )\n",
    "                    loss_G = -torch.mean(fake_logit)\n",
    "                    total_loss_G += loss_G.item()\n",
    "                    # Generator backwarding\n",
    "                    self.G.zero_grad()\n",
    "                    loss_G.backward()\n",
    "                    self.optimizer_G.step()\n",
    "            print(\"Epoch[{}/{}] loss_G : {:.6f} loss_D : {:.6f}\".format(ep + 1, self.config[\"epoch\"], total_loss_G / (self.refresh/self.config[\"n_critic\"]), total_loss_D / (self.refresh)))\n",
    "            if (ep + 1) % 5 == 0:\n",
    "                self.SaveEpochResult(ep)\n",
    "            if ep >= 100 and (ep + 1) % 10 == 0:\n",
    "                save_checkpoint(\"/data/allen/hw2model/sngangp_G_ep{}.pth\".format(ep + 1), self.G, self.optimizer_G)\n",
    "                save_checkpoint(\"/data/allen/hw2model/sngangp_D_ep{}.pth\".format(ep + 1), self.D, self.optimizer_D)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNGAN_GP = TrainGan(config)\n",
    "print(SNGAN_GP.G, SNGAN_GP.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38464\n",
      "Epoch[1/500] loss_G : 26.856668 loss_D : -21.220496\n",
      "Epoch[2/500] loss_G : 31.458643 loss_D : -13.720754\n",
      "Epoch[3/500] loss_G : 34.311541 loss_D : -11.039145\n",
      "Epoch[4/500] loss_G : 35.169863 loss_D : -8.399651\n",
      "Epoch[5/500] loss_G : 33.540571 loss_D : -6.861910\n",
      "Epoch[6/500] loss_G : 34.539854 loss_D : -6.243287\n",
      "Epoch[7/500] loss_G : 35.998614 loss_D : -5.951208\n",
      "Epoch[8/500] loss_G : 37.191012 loss_D : -5.779420\n",
      "Epoch[9/500] loss_G : 38.122981 loss_D : -5.720413\n",
      "Epoch[10/500] loss_G : 38.961808 loss_D : -5.583660\n",
      "Epoch[11/500] loss_G : 39.887662 loss_D : -5.544386\n",
      "Epoch[12/500] loss_G : 40.907555 loss_D : -5.452085\n",
      "Epoch[13/500] loss_G : 41.926163 loss_D : -5.326874\n",
      "Epoch[14/500] loss_G : 42.750660 loss_D : -5.155093\n",
      "Epoch[15/500] loss_G : 43.512206 loss_D : -5.016008\n",
      "Epoch[16/500] loss_G : 44.183177 loss_D : -4.888528\n",
      "Epoch[17/500] loss_G : 45.472748 loss_D : -4.693958\n",
      "Epoch[18/500] loss_G : 46.089792 loss_D : -4.567614\n",
      "Epoch[19/500] loss_G : 46.589586 loss_D : -4.401463\n",
      "Epoch[20/500] loss_G : 47.405534 loss_D : -4.232569\n",
      "Epoch[21/500] loss_G : 47.696733 loss_D : -4.089334\n",
      "Epoch[22/500] loss_G : 48.507848 loss_D : -3.968582\n",
      "Epoch[23/500] loss_G : 49.193590 loss_D : -3.878138\n",
      "Epoch[24/500] loss_G : 49.870595 loss_D : -3.757796\n",
      "Epoch[25/500] loss_G : 50.143087 loss_D : -3.527745\n",
      "Epoch[26/500] loss_G : 50.767317 loss_D : -3.591556\n",
      "Epoch[27/500] loss_G : 51.866306 loss_D : -3.512069\n",
      "Epoch[28/500] loss_G : 52.499976 loss_D : -3.437487\n",
      "Epoch[29/500] loss_G : 53.183233 loss_D : -3.381958\n",
      "Epoch[30/500] loss_G : 53.825711 loss_D : -3.304138\n",
      "Epoch[31/500] loss_G : 54.395794 loss_D : -3.239543\n",
      "Epoch[32/500] loss_G : 54.847829 loss_D : -3.174910\n",
      "Epoch[33/500] loss_G : 55.293439 loss_D : -3.117742\n",
      "Epoch[34/500] loss_G : 55.977801 loss_D : -3.064189\n",
      "Epoch[35/500] loss_G : 56.600335 loss_D : -3.011620\n",
      "Epoch[36/500] loss_G : 56.911377 loss_D : -2.985751\n",
      "Epoch[37/500] loss_G : 57.439549 loss_D : -2.923962\n",
      "Epoch[38/500] loss_G : 57.995307 loss_D : -2.900634\n",
      "Epoch[39/500] loss_G : 58.455804 loss_D : -2.855487\n",
      "Epoch[40/500] loss_G : 59.082584 loss_D : -2.815968\n",
      "Epoch[41/500] loss_G : 59.261785 loss_D : -2.764124\n",
      "Epoch[42/500] loss_G : 59.706824 loss_D : -2.724593\n",
      "Epoch[43/500] loss_G : 60.232952 loss_D : -2.703167\n",
      "Epoch[44/500] loss_G : 60.591415 loss_D : -2.671120\n",
      "Epoch[45/500] loss_G : 60.780911 loss_D : -2.643865\n",
      "Epoch[46/500] loss_G : 61.233955 loss_D : -2.611125\n",
      "Epoch[47/500] loss_G : 61.525433 loss_D : -2.568913\n",
      "Epoch[48/500] loss_G : 61.904547 loss_D : -2.533417\n",
      "Epoch[49/500] loss_G : 62.209864 loss_D : -2.506119\n",
      "Epoch[50/500] loss_G : 62.700167 loss_D : -2.485511\n",
      "Epoch[51/500] loss_G : 63.048167 loss_D : -2.455404\n",
      "Epoch[52/500] loss_G : 63.329854 loss_D : -2.425155\n",
      "Epoch[53/500] loss_G : 63.716297 loss_D : -2.434698\n",
      "Epoch[54/500] loss_G : 63.964996 loss_D : -2.384203\n",
      "Epoch[55/500] loss_G : 64.428339 loss_D : -2.386774\n",
      "Epoch[56/500] loss_G : 64.612222 loss_D : -2.355135\n",
      "Epoch[57/500] loss_G : 64.819108 loss_D : -2.342171\n",
      "Epoch[58/500] loss_G : 65.306152 loss_D : -2.309296\n",
      "Epoch[59/500] loss_G : 65.477477 loss_D : -2.303592\n",
      "Epoch[60/500] loss_G : 65.869066 loss_D : -2.294699\n",
      "Epoch[61/500] loss_G : 66.053612 loss_D : -2.270760\n",
      "Epoch[62/500] loss_G : 66.274790 loss_D : -2.235318\n",
      "Epoch[63/500] loss_G : 66.767053 loss_D : -2.252292\n",
      "Epoch[64/500] loss_G : 66.970696 loss_D : -2.246943\n",
      "Epoch[65/500] loss_G : 67.245972 loss_D : -2.205820\n",
      "Epoch[66/500] loss_G : 67.377687 loss_D : -2.202535\n",
      "Epoch[67/500] loss_G : 67.824254 loss_D : -2.172564\n",
      "Epoch[68/500] loss_G : 67.916297 loss_D : -2.172167\n",
      "Epoch[69/500] loss_G : 68.151621 loss_D : -2.164780\n",
      "Epoch[70/500] loss_G : 68.513665 loss_D : -2.150605\n",
      "Epoch[71/500] loss_G : 68.773712 loss_D : -2.126790\n",
      "Epoch[72/500] loss_G : 68.913189 loss_D : -2.125825\n",
      "Epoch[73/500] loss_G : 69.205930 loss_D : -2.107405\n",
      "Epoch[74/500] loss_G : 69.293785 loss_D : -2.104824\n",
      "Epoch[75/500] loss_G : 69.446703 loss_D : -2.083176\n",
      "Epoch[76/500] loss_G : 69.882408 loss_D : -2.086470\n",
      "Epoch[77/500] loss_G : 70.094549 loss_D : -2.066208\n",
      "Epoch[78/500] loss_G : 70.292276 loss_D : -2.048386\n",
      "Epoch[79/500] loss_G : 70.474540 loss_D : -2.045413\n",
      "Epoch[80/500] loss_G : 70.879298 loss_D : -2.031543\n",
      "Epoch[81/500] loss_G : 71.168981 loss_D : -2.016477\n",
      "Epoch[82/500] loss_G : 71.333762 loss_D : -2.016985\n",
      "Epoch[83/500] loss_G : 71.664511 loss_D : -2.001070\n",
      "Epoch[84/500] loss_G : 71.840083 loss_D : -2.006762\n",
      "Epoch[85/500] loss_G : 72.060917 loss_D : -1.989075\n",
      "Epoch[86/500] loss_G : 72.066532 loss_D : -1.983076\n",
      "Epoch[87/500] loss_G : 72.439512 loss_D : -1.962027\n",
      "Epoch[88/500] loss_G : 72.526481 loss_D : -1.961194\n",
      "Epoch[89/500] loss_G : 72.653853 loss_D : -1.929592\n",
      "Epoch[90/500] loss_G : 73.096130 loss_D : -1.949191\n",
      "Epoch[91/500] loss_G : 73.029662 loss_D : -1.919313\n",
      "Epoch[92/500] loss_G : 73.379240 loss_D : -1.919349\n",
      "Epoch[93/500] loss_G : 73.775514 loss_D : -1.894589\n",
      "Epoch[94/500] loss_G : 73.947766 loss_D : -1.898350\n",
      "Epoch[95/500] loss_G : 73.899747 loss_D : -1.892517\n",
      "Epoch[96/500] loss_G : 74.498169 loss_D : -1.895096\n",
      "Epoch[97/500] loss_G : 74.495431 loss_D : -1.894008\n",
      "Epoch[98/500] loss_G : 74.911064 loss_D : -1.889610\n",
      "Epoch[99/500] loss_G : 75.165176 loss_D : -1.879425\n",
      "Epoch[100/500] loss_G : 75.420605 loss_D : -1.864189\n",
      "Epoch[101/500] loss_G : 75.786357 loss_D : -1.853132\n",
      "Epoch[102/500] loss_G : 76.050535 loss_D : -1.851334\n",
      "Epoch[103/500] loss_G : 76.131004 loss_D : -1.843845\n",
      "Epoch[104/500] loss_G : 76.608879 loss_D : -1.835606\n",
      "Epoch[105/500] loss_G : 76.747954 loss_D : -1.839707\n",
      "Epoch[106/500] loss_G : 77.012753 loss_D : -1.839684\n",
      "Epoch[107/500] loss_G : 77.071621 loss_D : -1.815842\n",
      "Epoch[108/500] loss_G : 77.253678 loss_D : -1.838178\n",
      "Epoch[109/500] loss_G : 77.593950 loss_D : -1.829273\n",
      "Epoch[110/500] loss_G : 77.764395 loss_D : -1.805241\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep110.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep110.pth\n",
      "Epoch[111/500] loss_G : 78.068415 loss_D : -1.809522\n",
      "Epoch[112/500] loss_G : 78.480900 loss_D : -1.815820\n",
      "Epoch[113/500] loss_G : 78.654753 loss_D : -1.807353\n",
      "Epoch[114/500] loss_G : 78.813684 loss_D : -1.799426\n",
      "Epoch[115/500] loss_G : 79.117365 loss_D : -1.823305\n",
      "Epoch[116/500] loss_G : 79.525549 loss_D : -1.802691\n",
      "Epoch[117/500] loss_G : 79.833486 loss_D : -1.790050\n",
      "Epoch[118/500] loss_G : 80.000143 loss_D : -1.792951\n",
      "Epoch[119/500] loss_G : 80.321115 loss_D : -1.777721\n",
      "Epoch[120/500] loss_G : 80.604872 loss_D : -1.783611\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep120.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep120.pth\n",
      "Epoch[121/500] loss_G : 80.790569 loss_D : -1.775745\n",
      "Epoch[122/500] loss_G : 81.192469 loss_D : -1.804295\n",
      "Epoch[123/500] loss_G : 81.277673 loss_D : -1.781999\n",
      "Epoch[124/500] loss_G : 81.512867 loss_D : -1.774422\n",
      "Epoch[125/500] loss_G : 81.472178 loss_D : -1.767530\n",
      "Epoch[126/500] loss_G : 81.956087 loss_D : -1.774696\n",
      "Epoch[127/500] loss_G : 82.192831 loss_D : -1.756752\n",
      "Epoch[128/500] loss_G : 82.657441 loss_D : -1.775387\n",
      "Epoch[129/500] loss_G : 82.792355 loss_D : -1.764471\n",
      "Epoch[130/500] loss_G : 82.903876 loss_D : -1.749358\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep130.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep130.pth\n",
      "Epoch[131/500] loss_G : 83.401053 loss_D : -1.766485\n",
      "Epoch[132/500] loss_G : 83.389653 loss_D : -1.744921\n",
      "Epoch[133/500] loss_G : 83.726336 loss_D : -1.741425\n",
      "Epoch[134/500] loss_G : 84.067530 loss_D : -1.749629\n",
      "Epoch[135/500] loss_G : 84.195257 loss_D : -1.746591\n",
      "Epoch[136/500] loss_G : 84.478029 loss_D : -1.749285\n",
      "Epoch[137/500] loss_G : 84.948625 loss_D : -1.748212\n",
      "Epoch[138/500] loss_G : 85.234828 loss_D : -1.750382\n",
      "Epoch[139/500] loss_G : 85.491898 loss_D : -1.741743\n",
      "Epoch[140/500] loss_G : 85.998407 loss_D : -1.754946\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep140.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep140.pth\n",
      "Epoch[141/500] loss_G : 86.067962 loss_D : -1.743897\n",
      "Epoch[142/500] loss_G : 86.388670 loss_D : -1.733843\n",
      "Epoch[143/500] loss_G : 86.568642 loss_D : -1.736581\n",
      "Epoch[144/500] loss_G : 86.932034 loss_D : -1.735356\n",
      "Epoch[145/500] loss_G : 87.137700 loss_D : -1.738364\n",
      "Epoch[146/500] loss_G : 87.397996 loss_D : -1.724007\n",
      "Epoch[147/500] loss_G : 87.653922 loss_D : -1.747548\n",
      "Epoch[148/500] loss_G : 88.164465 loss_D : -1.748412\n",
      "Epoch[149/500] loss_G : 88.230799 loss_D : -1.717325\n",
      "Epoch[150/500] loss_G : 88.734307 loss_D : -1.736040\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep150.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep150.pth\n",
      "Epoch[151/500] loss_G : 88.797266 loss_D : -1.734493\n",
      "Epoch[152/500] loss_G : 89.283348 loss_D : -1.732027\n",
      "Epoch[153/500] loss_G : 89.583362 loss_D : -1.736308\n",
      "Epoch[154/500] loss_G : 89.792654 loss_D : -1.715746\n",
      "Epoch[155/500] loss_G : 89.937553 loss_D : -1.737534\n",
      "Epoch[156/500] loss_G : 90.227958 loss_D : -1.743694\n",
      "Epoch[157/500] loss_G : 90.382123 loss_D : -1.731266\n",
      "Epoch[158/500] loss_G : 90.873221 loss_D : -1.736271\n",
      "Epoch[159/500] loss_G : 91.144631 loss_D : -1.743692\n",
      "Epoch[160/500] loss_G : 91.299796 loss_D : -1.738905\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep160.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep160.pth\n",
      "Epoch[161/500] loss_G : 91.745139 loss_D : -1.738316\n",
      "Epoch[162/500] loss_G : 92.089611 loss_D : -1.743022\n",
      "Epoch[163/500] loss_G : 92.223146 loss_D : -1.738509\n",
      "Epoch[164/500] loss_G : 92.533360 loss_D : -1.742254\n",
      "Epoch[165/500] loss_G : 92.885601 loss_D : -1.743672\n",
      "Epoch[166/500] loss_G : 93.114148 loss_D : -1.750353\n",
      "Epoch[167/500] loss_G : 93.566750 loss_D : -1.734555\n",
      "Epoch[168/500] loss_G : 93.722814 loss_D : -1.735043\n",
      "Epoch[169/500] loss_G : 94.142802 loss_D : -1.735404\n",
      "Epoch[170/500] loss_G : 94.240941 loss_D : -1.724898\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep170.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep170.pth\n",
      "Epoch[171/500] loss_G : 94.652979 loss_D : -1.740738\n",
      "Epoch[172/500] loss_G : 94.912124 loss_D : -1.740016\n",
      "Epoch[173/500] loss_G : 95.238559 loss_D : -1.743646\n",
      "Epoch[174/500] loss_G : 95.549814 loss_D : -1.741251\n",
      "Epoch[175/500] loss_G : 95.979905 loss_D : -1.747731\n",
      "Epoch[176/500] loss_G : 96.319433 loss_D : -1.746287\n",
      "Epoch[177/500] loss_G : 96.368873 loss_D : -1.733753\n",
      "Epoch[178/500] loss_G : 96.780843 loss_D : -1.751974\n",
      "Epoch[179/500] loss_G : 96.922144 loss_D : -1.737007\n",
      "Epoch[180/500] loss_G : 97.355170 loss_D : -1.738896\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep180.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep180.pth\n",
      "Epoch[181/500] loss_G : 97.467298 loss_D : -1.732587\n",
      "Epoch[182/500] loss_G : 98.031754 loss_D : -1.740560\n",
      "Epoch[183/500] loss_G : 98.160327 loss_D : -1.747307\n",
      "Epoch[184/500] loss_G : 98.566639 loss_D : -1.740276\n",
      "Epoch[185/500] loss_G : 98.811997 loss_D : -1.748640\n",
      "Epoch[186/500] loss_G : 99.092403 loss_D : -1.751548\n",
      "Epoch[187/500] loss_G : 99.315964 loss_D : -1.750078\n",
      "Epoch[188/500] loss_G : 99.598212 loss_D : -1.750174\n",
      "Epoch[189/500] loss_G : 99.931308 loss_D : -1.765962\n",
      "Epoch[190/500] loss_G : 100.364812 loss_D : -1.752856\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep190.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep190.pth\n",
      "Epoch[191/500] loss_G : 100.513763 loss_D : -1.738758\n",
      "Epoch[192/500] loss_G : 100.740332 loss_D : -1.769309\n",
      "Epoch[193/500] loss_G : 101.125699 loss_D : -1.762501\n",
      "Epoch[194/500] loss_G : 101.574564 loss_D : -1.760107\n",
      "Epoch[195/500] loss_G : 101.870888 loss_D : -1.755494\n",
      "Epoch[196/500] loss_G : 102.050326 loss_D : -1.760052\n",
      "Epoch[197/500] loss_G : 102.363905 loss_D : -1.754983\n",
      "Epoch[198/500] loss_G : 102.413829 loss_D : -1.746879\n",
      "Epoch[199/500] loss_G : 102.839453 loss_D : -1.782200\n",
      "Epoch[200/500] loss_G : 103.392607 loss_D : -1.759645\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep200.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep200.pth\n",
      "Epoch[201/500] loss_G : 103.809304 loss_D : -1.771976\n",
      "Epoch[202/500] loss_G : 104.060935 loss_D : -1.766602\n",
      "Epoch[203/500] loss_G : 104.178509 loss_D : -1.761651\n",
      "Epoch[204/500] loss_G : 104.434592 loss_D : -1.764320\n",
      "Epoch[205/500] loss_G : 104.619865 loss_D : -1.778768\n",
      "Epoch[206/500] loss_G : 105.135447 loss_D : -1.772568\n",
      "Epoch[207/500] loss_G : 105.350105 loss_D : -1.768914\n",
      "Epoch[208/500] loss_G : 105.774571 loss_D : -1.779988\n",
      "Epoch[209/500] loss_G : 105.979320 loss_D : -1.773513\n",
      "Epoch[210/500] loss_G : 106.320669 loss_D : -1.778773\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep210.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep210.pth\n",
      "Epoch[211/500] loss_G : 106.590643 loss_D : -1.787890\n",
      "Epoch[212/500] loss_G : 106.983946 loss_D : -1.777323\n",
      "Epoch[213/500] loss_G : 107.197704 loss_D : -1.778530\n",
      "Epoch[214/500] loss_G : 107.546833 loss_D : -1.788444\n",
      "Epoch[215/500] loss_G : 107.797955 loss_D : -1.785581\n",
      "Epoch[216/500] loss_G : 108.142631 loss_D : -1.788925\n",
      "Epoch[217/500] loss_G : 108.475412 loss_D : -1.802314\n",
      "Epoch[218/500] loss_G : 108.803362 loss_D : -1.792956\n",
      "Epoch[219/500] loss_G : 109.108132 loss_D : -1.803100\n",
      "Epoch[220/500] loss_G : 109.346794 loss_D : -1.809049\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep220.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep220.pth\n",
      "Epoch[221/500] loss_G : 109.790046 loss_D : -1.801864\n",
      "Epoch[222/500] loss_G : 109.957068 loss_D : -1.802428\n",
      "Epoch[223/500] loss_G : 110.222888 loss_D : -1.799521\n",
      "Epoch[224/500] loss_G : 110.516395 loss_D : -1.808162\n",
      "Epoch[225/500] loss_G : 111.079123 loss_D : -1.825812\n",
      "Epoch[226/500] loss_G : 111.185805 loss_D : -1.812870\n",
      "Epoch[227/500] loss_G : 111.460012 loss_D : -1.809638\n",
      "Epoch[228/500] loss_G : 111.731183 loss_D : -1.813374\n",
      "Epoch[229/500] loss_G : 112.133494 loss_D : -1.817654\n",
      "Epoch[230/500] loss_G : 112.451696 loss_D : -1.809668\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep230.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep230.pth\n",
      "Epoch[231/500] loss_G : 112.653283 loss_D : -1.808384\n",
      "Epoch[232/500] loss_G : 112.877030 loss_D : -1.820273\n",
      "Epoch[233/500] loss_G : 113.238479 loss_D : -1.817369\n",
      "Epoch[234/500] loss_G : 113.736674 loss_D : -1.824740\n",
      "Epoch[235/500] loss_G : 113.893718 loss_D : -1.819374\n",
      "Epoch[236/500] loss_G : 114.167594 loss_D : -1.832555\n",
      "Epoch[237/500] loss_G : 114.591904 loss_D : -1.828919\n",
      "Epoch[238/500] loss_G : 114.961906 loss_D : -1.831988\n",
      "Epoch[239/500] loss_G : 115.173613 loss_D : -1.841520\n",
      "Epoch[240/500] loss_G : 115.614103 loss_D : -1.854407\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep240.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep240.pth\n",
      "Epoch[241/500] loss_G : 116.020266 loss_D : -1.836336\n",
      "Epoch[242/500] loss_G : 116.214225 loss_D : -1.836030\n",
      "Epoch[243/500] loss_G : 116.507981 loss_D : -1.854299\n",
      "Epoch[244/500] loss_G : 116.866308 loss_D : -1.867569\n",
      "Epoch[245/500] loss_G : 117.172677 loss_D : -1.846536\n",
      "Epoch[246/500] loss_G : 117.522553 loss_D : -1.864128\n",
      "Epoch[247/500] loss_G : 117.995270 loss_D : -1.857264\n",
      "Epoch[248/500] loss_G : 118.216456 loss_D : -1.858991\n",
      "Epoch[249/500] loss_G : 118.535664 loss_D : -1.863325\n",
      "Epoch[250/500] loss_G : 118.857038 loss_D : -1.871050\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep250.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep250.pth\n",
      "Epoch[251/500] loss_G : 119.162013 loss_D : -1.864883\n",
      "Epoch[252/500] loss_G : 119.695245 loss_D : -1.873746\n",
      "Epoch[253/500] loss_G : 119.852766 loss_D : -1.870701\n",
      "Epoch[254/500] loss_G : 120.252444 loss_D : -1.888710\n",
      "Epoch[255/500] loss_G : 120.538866 loss_D : -1.871271\n",
      "Epoch[256/500] loss_G : 120.888125 loss_D : -1.877835\n",
      "Epoch[257/500] loss_G : 121.173071 loss_D : -1.892416\n",
      "Epoch[258/500] loss_G : 121.419750 loss_D : -1.893909\n",
      "Epoch[259/500] loss_G : 121.747271 loss_D : -1.894597\n",
      "Epoch[260/500] loss_G : 122.174063 loss_D : -1.897184\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep260.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep260.pth\n",
      "Epoch[261/500] loss_G : 122.498834 loss_D : -1.899534\n",
      "Epoch[262/500] loss_G : 122.768444 loss_D : -1.912480\n",
      "Epoch[263/500] loss_G : 123.069340 loss_D : -1.910366\n",
      "Epoch[264/500] loss_G : 123.323447 loss_D : -1.907974\n",
      "Epoch[265/500] loss_G : 123.591067 loss_D : -1.912176\n",
      "Epoch[266/500] loss_G : 124.314315 loss_D : -1.903328\n",
      "Epoch[267/500] loss_G : 124.373318 loss_D : -1.906599\n",
      "Epoch[268/500] loss_G : 124.695443 loss_D : -1.919167\n",
      "Epoch[269/500] loss_G : 125.221392 loss_D : -1.916616\n",
      "Epoch[270/500] loss_G : 125.308489 loss_D : -1.926614\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep270.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep270.pth\n",
      "Epoch[271/500] loss_G : 125.563626 loss_D : -1.918976\n",
      "Epoch[272/500] loss_G : 125.954948 loss_D : -1.924980\n",
      "Epoch[273/500] loss_G : 126.315756 loss_D : -1.933045\n",
      "Epoch[274/500] loss_G : 126.442793 loss_D : -1.931700\n",
      "Epoch[275/500] loss_G : 126.933019 loss_D : -1.945575\n",
      "Epoch[276/500] loss_G : 127.211317 loss_D : -1.928714\n",
      "Epoch[277/500] loss_G : 127.645818 loss_D : -1.938979\n",
      "Epoch[278/500] loss_G : 127.986348 loss_D : -1.951601\n",
      "Epoch[279/500] loss_G : 128.258060 loss_D : -1.931522\n",
      "Epoch[280/500] loss_G : 128.614497 loss_D : -1.940268\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep280.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep280.pth\n",
      "Epoch[281/500] loss_G : 129.026878 loss_D : -1.953070\n",
      "Epoch[282/500] loss_G : 129.243666 loss_D : -1.964709\n",
      "Epoch[283/500] loss_G : 129.678309 loss_D : -1.965263\n",
      "Epoch[284/500] loss_G : 130.047474 loss_D : -1.977892\n",
      "Epoch[285/500] loss_G : 130.271277 loss_D : -1.955237\n",
      "Epoch[286/500] loss_G : 130.424525 loss_D : -1.961109\n",
      "Epoch[287/500] loss_G : 131.014357 loss_D : -1.977837\n",
      "Epoch[288/500] loss_G : 131.351429 loss_D : -1.979722\n",
      "Epoch[289/500] loss_G : 131.799494 loss_D : -1.976664\n",
      "Epoch[290/500] loss_G : 132.112483 loss_D : -1.982893\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep290.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep290.pth\n",
      "Epoch[291/500] loss_G : 132.273318 loss_D : -1.984149\n",
      "Epoch[292/500] loss_G : 132.749431 loss_D : -1.975120\n",
      "Epoch[293/500] loss_G : 133.159330 loss_D : -1.991202\n",
      "Epoch[294/500] loss_G : 133.382726 loss_D : -1.996598\n",
      "Epoch[295/500] loss_G : 133.488631 loss_D : -1.997797\n",
      "Epoch[296/500] loss_G : 133.950792 loss_D : -1.999522\n",
      "Epoch[297/500] loss_G : 134.282516 loss_D : -1.999129\n",
      "Epoch[298/500] loss_G : 134.573426 loss_D : -1.998492\n",
      "Epoch[299/500] loss_G : 135.026906 loss_D : -1.996766\n",
      "Epoch[300/500] loss_G : 135.361981 loss_D : -2.005798\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep300.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep300.pth\n",
      "Epoch[301/500] loss_G : 135.663565 loss_D : -2.012150\n",
      "Epoch[302/500] loss_G : 135.915802 loss_D : -2.007734\n",
      "Epoch[303/500] loss_G : 136.442894 loss_D : -2.011325\n",
      "Epoch[304/500] loss_G : 136.434166 loss_D : -2.013087\n",
      "Epoch[305/500] loss_G : 136.709167 loss_D : -2.026840\n",
      "Epoch[306/500] loss_G : 137.145905 loss_D : -2.024153\n",
      "Epoch[307/500] loss_G : 137.433859 loss_D : -2.030686\n",
      "Epoch[308/500] loss_G : 138.020378 loss_D : -2.037014\n",
      "Epoch[309/500] loss_G : 138.112909 loss_D : -2.045728\n",
      "Epoch[310/500] loss_G : 138.476289 loss_D : -2.027763\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep310.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep310.pth\n",
      "Epoch[311/500] loss_G : 138.751990 loss_D : -2.038193\n",
      "Epoch[312/500] loss_G : 139.200077 loss_D : -2.043424\n",
      "Epoch[313/500] loss_G : 139.718064 loss_D : -2.053226\n",
      "Epoch[314/500] loss_G : 139.768939 loss_D : -2.033744\n",
      "Epoch[315/500] loss_G : 140.319355 loss_D : -2.054163\n",
      "Epoch[316/500] loss_G : 140.534404 loss_D : -2.043222\n",
      "Epoch[317/500] loss_G : 140.806211 loss_D : -2.057484\n",
      "Epoch[318/500] loss_G : 141.229678 loss_D : -2.059668\n",
      "Epoch[319/500] loss_G : 141.429478 loss_D : -2.059524\n",
      "Epoch[320/500] loss_G : 141.778196 loss_D : -2.066715\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep320.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep320.pth\n",
      "Epoch[321/500] loss_G : 142.391788 loss_D : -2.072998\n",
      "Epoch[322/500] loss_G : 142.561793 loss_D : -2.081864\n",
      "Epoch[323/500] loss_G : 142.722804 loss_D : -2.076798\n",
      "Epoch[324/500] loss_G : 143.362835 loss_D : -2.082921\n",
      "Epoch[325/500] loss_G : 143.820002 loss_D : -2.067663\n",
      "Epoch[326/500] loss_G : 143.931089 loss_D : -2.074177\n",
      "Epoch[327/500] loss_G : 144.245401 loss_D : -2.085893\n",
      "Epoch[328/500] loss_G : 144.658096 loss_D : -2.086711\n",
      "Epoch[329/500] loss_G : 144.927549 loss_D : -2.086006\n",
      "Epoch[330/500] loss_G : 145.291855 loss_D : -2.087881\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep330.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep330.pth\n",
      "Epoch[331/500] loss_G : 145.523321 loss_D : -2.112255\n",
      "Epoch[332/500] loss_G : 145.924177 loss_D : -2.110613\n",
      "Epoch[333/500] loss_G : 146.194108 loss_D : -2.116416\n",
      "Epoch[334/500] loss_G : 146.615848 loss_D : -2.116569\n",
      "Epoch[335/500] loss_G : 147.058698 loss_D : -2.101260\n",
      "Epoch[336/500] loss_G : 147.365582 loss_D : -2.110066\n",
      "Epoch[337/500] loss_G : 147.546293 loss_D : -2.120763\n",
      "Epoch[338/500] loss_G : 148.069652 loss_D : -2.110822\n",
      "Epoch[339/500] loss_G : 148.203266 loss_D : -2.122557\n",
      "Epoch[340/500] loss_G : 148.615087 loss_D : -2.118205\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep340.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep340.pth\n",
      "Epoch[341/500] loss_G : 148.998858 loss_D : -2.122634\n",
      "Epoch[342/500] loss_G : 149.145321 loss_D : -2.121287\n",
      "Epoch[343/500] loss_G : 149.663739 loss_D : -2.120322\n",
      "Epoch[344/500] loss_G : 149.920257 loss_D : -2.134750\n",
      "Epoch[345/500] loss_G : 150.340241 loss_D : -2.130506\n",
      "Epoch[346/500] loss_G : 150.359745 loss_D : -2.150480\n",
      "Epoch[347/500] loss_G : 150.931884 loss_D : -2.145242\n",
      "Epoch[348/500] loss_G : 151.163846 loss_D : -2.139151\n",
      "Epoch[349/500] loss_G : 151.667411 loss_D : -2.139709\n",
      "Epoch[350/500] loss_G : 152.004172 loss_D : -2.153956\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep350.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep350.pth\n",
      "Epoch[351/500] loss_G : 152.338399 loss_D : -2.151795\n",
      "Epoch[352/500] loss_G : 152.763471 loss_D : -2.161428\n",
      "Epoch[353/500] loss_G : 152.844031 loss_D : -2.172301\n",
      "Epoch[354/500] loss_G : 153.281577 loss_D : -2.167415\n",
      "Epoch[355/500] loss_G : 153.765429 loss_D : -2.175225\n",
      "Epoch[356/500] loss_G : 153.968770 loss_D : -2.175999\n",
      "Epoch[357/500] loss_G : 154.453533 loss_D : -2.185703\n",
      "Epoch[358/500] loss_G : 154.914997 loss_D : -2.178289\n",
      "Epoch[359/500] loss_G : 155.251081 loss_D : -2.179744\n",
      "Epoch[360/500] loss_G : 155.648095 loss_D : -2.175115\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep360.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep360.pth\n",
      "Epoch[361/500] loss_G : 155.829434 loss_D : -2.190293\n",
      "Epoch[362/500] loss_G : 156.122441 loss_D : -2.192044\n",
      "Epoch[363/500] loss_G : 156.290223 loss_D : -2.181271\n",
      "Epoch[364/500] loss_G : 156.660444 loss_D : -2.189123\n",
      "Epoch[365/500] loss_G : 156.723852 loss_D : -2.186936\n",
      "Epoch[366/500] loss_G : 157.424430 loss_D : -2.198344\n",
      "Epoch[367/500] loss_G : 157.512334 loss_D : -2.187684\n",
      "Epoch[368/500] loss_G : 157.928203 loss_D : -2.207363\n",
      "Epoch[369/500] loss_G : 158.131166 loss_D : -2.194174\n",
      "Epoch[370/500] loss_G : 158.669068 loss_D : -2.196166\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep370.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep370.pth\n",
      "Epoch[371/500] loss_G : 158.998181 loss_D : -2.223262\n",
      "Epoch[372/500] loss_G : 159.412712 loss_D : -2.228083\n",
      "Epoch[373/500] loss_G : 159.784827 loss_D : -2.211248\n",
      "Epoch[374/500] loss_G : 159.892140 loss_D : -2.227472\n",
      "Epoch[375/500] loss_G : 160.299051 loss_D : -2.225760\n",
      "Epoch[376/500] loss_G : 160.525003 loss_D : -2.235834\n",
      "Epoch[377/500] loss_G : 160.857781 loss_D : -2.214374\n",
      "Epoch[378/500] loss_G : 161.166274 loss_D : -2.221892\n",
      "Epoch[379/500] loss_G : 161.605923 loss_D : -2.238063\n",
      "Epoch[380/500] loss_G : 161.787220 loss_D : -2.237046\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep380.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep380.pth\n",
      "Epoch[381/500] loss_G : 161.919053 loss_D : -2.243740\n",
      "Epoch[382/500] loss_G : 162.466147 loss_D : -2.238140\n",
      "Epoch[383/500] loss_G : 163.008226 loss_D : -2.244548\n",
      "Epoch[384/500] loss_G : 163.510638 loss_D : -2.247275\n",
      "Epoch[385/500] loss_G : 163.667784 loss_D : -2.248837\n",
      "Epoch[386/500] loss_G : 164.043412 loss_D : -2.262699\n",
      "Epoch[387/500] loss_G : 164.463963 loss_D : -2.261846\n",
      "Epoch[388/500] loss_G : 164.713055 loss_D : -2.266339\n",
      "Epoch[389/500] loss_G : 164.862257 loss_D : -2.256174\n",
      "Epoch[390/500] loss_G : 165.259394 loss_D : -2.271211\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep390.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep390.pth\n",
      "Epoch[391/500] loss_G : 165.481895 loss_D : -2.260780\n",
      "Epoch[392/500] loss_G : 166.056466 loss_D : -2.254845\n",
      "Epoch[393/500] loss_G : 166.365512 loss_D : -2.273086\n",
      "Epoch[394/500] loss_G : 166.881993 loss_D : -2.257560\n",
      "Epoch[395/500] loss_G : 167.320756 loss_D : -2.262210\n",
      "Epoch[396/500] loss_G : 167.849436 loss_D : -2.283567\n",
      "Epoch[397/500] loss_G : 167.679851 loss_D : -2.281014\n",
      "Epoch[398/500] loss_G : 168.203355 loss_D : -2.287413\n",
      "Epoch[399/500] loss_G : 168.764680 loss_D : -2.302966\n",
      "Epoch[400/500] loss_G : 168.784665 loss_D : -2.305831\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep400.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep400.pth\n",
      "Epoch[401/500] loss_G : 169.261594 loss_D : -2.287228\n",
      "Epoch[402/500] loss_G : 169.394481 loss_D : -2.282045\n",
      "Epoch[403/500] loss_G : 169.843141 loss_D : -2.296669\n",
      "Epoch[404/500] loss_G : 170.332969 loss_D : -2.288059\n",
      "Epoch[405/500] loss_G : 170.520730 loss_D : -2.308115\n",
      "Epoch[406/500] loss_G : 170.970858 loss_D : -2.308295\n",
      "Epoch[407/500] loss_G : 171.514577 loss_D : -2.323754\n",
      "Epoch[408/500] loss_G : 171.898335 loss_D : -2.306571\n",
      "Epoch[409/500] loss_G : 172.348157 loss_D : -2.332233\n",
      "Epoch[410/500] loss_G : 172.347132 loss_D : -2.315437\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep410.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep410.pth\n",
      "Epoch[411/500] loss_G : 172.619791 loss_D : -2.324105\n",
      "Epoch[412/500] loss_G : 172.967128 loss_D : -2.329905\n",
      "Epoch[413/500] loss_G : 173.425136 loss_D : -2.322828\n",
      "Epoch[414/500] loss_G : 173.572036 loss_D : -2.340719\n",
      "Epoch[415/500] loss_G : 174.009212 loss_D : -2.328307\n",
      "Epoch[416/500] loss_G : 174.189303 loss_D : -2.339980\n",
      "Epoch[417/500] loss_G : 174.669659 loss_D : -2.343615\n",
      "Epoch[418/500] loss_G : 175.193075 loss_D : -2.333861\n",
      "Epoch[419/500] loss_G : 175.473014 loss_D : -2.357978\n",
      "Epoch[420/500] loss_G : 175.511679 loss_D : -2.339972\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep420.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep420.pth\n",
      "Epoch[421/500] loss_G : 175.913608 loss_D : -2.348785\n",
      "Epoch[422/500] loss_G : 176.103468 loss_D : -2.362699\n",
      "Epoch[423/500] loss_G : 176.475934 loss_D : -2.363238\n",
      "Epoch[424/500] loss_G : 177.265587 loss_D : -2.358443\n",
      "Epoch[425/500] loss_G : 177.383247 loss_D : -2.370482\n",
      "Epoch[426/500] loss_G : 177.773492 loss_D : -2.368202\n",
      "Epoch[427/500] loss_G : 178.150746 loss_D : -2.348425\n",
      "Epoch[428/500] loss_G : 178.330442 loss_D : -2.371382\n",
      "Epoch[429/500] loss_G : 178.317359 loss_D : -2.352019\n",
      "Epoch[430/500] loss_G : 178.909321 loss_D : -2.381855\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep430.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep430.pth\n",
      "Epoch[431/500] loss_G : 179.208238 loss_D : -2.361113\n",
      "Epoch[432/500] loss_G : 179.489808 loss_D : -2.374206\n",
      "Epoch[433/500] loss_G : 179.990216 loss_D : -2.399360\n",
      "Epoch[434/500] loss_G : 179.985855 loss_D : -2.377076\n",
      "Epoch[435/500] loss_G : 180.416965 loss_D : -2.390606\n",
      "Epoch[436/500] loss_G : 180.590459 loss_D : -2.384197\n",
      "Epoch[437/500] loss_G : 180.882912 loss_D : -2.415244\n",
      "Epoch[438/500] loss_G : 181.134268 loss_D : -2.382471\n",
      "Epoch[439/500] loss_G : 181.605352 loss_D : -2.406788\n",
      "Epoch[440/500] loss_G : 182.220632 loss_D : -2.391405\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep440.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep440.pth\n",
      "Epoch[441/500] loss_G : 182.349308 loss_D : -2.419340\n",
      "Epoch[442/500] loss_G : 182.975035 loss_D : -2.407944\n",
      "Epoch[443/500] loss_G : 183.128618 loss_D : -2.421677\n",
      "Epoch[444/500] loss_G : 183.299177 loss_D : -2.415817\n",
      "Epoch[445/500] loss_G : 183.824217 loss_D : -2.424512\n",
      "Epoch[446/500] loss_G : 184.018399 loss_D : -2.415796\n",
      "Epoch[447/500] loss_G : 184.730628 loss_D : -2.438672\n",
      "Epoch[448/500] loss_G : 185.126155 loss_D : -2.425111\n",
      "Epoch[449/500] loss_G : 185.298167 loss_D : -2.425223\n",
      "Epoch[450/500] loss_G : 185.523045 loss_D : -2.430956\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep450.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep450.pth\n",
      "Epoch[451/500] loss_G : 185.858472 loss_D : -2.428223\n",
      "Epoch[452/500] loss_G : 186.271992 loss_D : -2.431284\n",
      "Epoch[453/500] loss_G : 186.538511 loss_D : -2.426033\n",
      "Epoch[454/500] loss_G : 187.085659 loss_D : -2.437112\n",
      "Epoch[455/500] loss_G : 187.289241 loss_D : -2.440050\n",
      "Epoch[456/500] loss_G : 187.376975 loss_D : -2.445214\n",
      "Epoch[457/500] loss_G : 187.623820 loss_D : -2.444547\n",
      "Epoch[458/500] loss_G : 188.129739 loss_D : -2.449493\n",
      "Epoch[459/500] loss_G : 188.361264 loss_D : -2.451472\n",
      "Epoch[460/500] loss_G : 188.945091 loss_D : -2.474209\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep460.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep460.pth\n",
      "Epoch[461/500] loss_G : 189.249907 loss_D : -2.476165\n",
      "Epoch[462/500] loss_G : 189.706623 loss_D : -2.465525\n",
      "Epoch[463/500] loss_G : 190.303840 loss_D : -2.459813\n",
      "Epoch[464/500] loss_G : 190.060932 loss_D : -2.470577\n",
      "Epoch[465/500] loss_G : 190.371153 loss_D : -2.463730\n",
      "Epoch[466/500] loss_G : 190.726117 loss_D : -2.468770\n",
      "Epoch[467/500] loss_G : 191.206130 loss_D : -2.498473\n",
      "Epoch[468/500] loss_G : 191.615856 loss_D : -2.481383\n",
      "Epoch[469/500] loss_G : 192.021019 loss_D : -2.485725\n",
      "Epoch[470/500] loss_G : 192.189843 loss_D : -2.476737\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep470.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep470.pth\n",
      "Epoch[471/500] loss_G : 192.538486 loss_D : -2.483979\n",
      "Epoch[472/500] loss_G : 192.821049 loss_D : -2.492777\n",
      "Epoch[473/500] loss_G : 193.180465 loss_D : -2.493566\n",
      "Epoch[474/500] loss_G : 193.456091 loss_D : -2.502672\n",
      "Epoch[475/500] loss_G : 194.049008 loss_D : -2.503273\n",
      "Epoch[476/500] loss_G : 194.460069 loss_D : -2.491358\n",
      "Epoch[477/500] loss_G : 194.490950 loss_D : -2.507734\n",
      "Epoch[478/500] loss_G : 195.218111 loss_D : -2.503567\n",
      "Epoch[479/500] loss_G : 195.440254 loss_D : -2.490353\n",
      "Epoch[480/500] loss_G : 195.597066 loss_D : -2.514178\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep480.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep480.pth\n",
      "Epoch[481/500] loss_G : 195.699844 loss_D : -2.517040\n",
      "Epoch[482/500] loss_G : 196.104690 loss_D : -2.534466\n",
      "Epoch[483/500] loss_G : 196.433480 loss_D : -2.515342\n",
      "Epoch[484/500] loss_G : 196.920437 loss_D : -2.521878\n",
      "Epoch[485/500] loss_G : 197.247216 loss_D : -2.512789\n",
      "Epoch[486/500] loss_G : 197.745547 loss_D : -2.529790\n",
      "Epoch[487/500] loss_G : 197.792399 loss_D : -2.540616\n",
      "Epoch[488/500] loss_G : 198.528600 loss_D : -2.527036\n",
      "Epoch[489/500] loss_G : 198.714266 loss_D : -2.533192\n",
      "Epoch[490/500] loss_G : 198.782192 loss_D : -2.521164\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep490.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep490.pth\n",
      "Epoch[491/500] loss_G : 199.488547 loss_D : -2.537834\n",
      "Epoch[492/500] loss_G : 199.583451 loss_D : -2.539393\n",
      "Epoch[493/500] loss_G : 199.827109 loss_D : -2.528581\n",
      "Epoch[494/500] loss_G : 200.428238 loss_D : -2.554404\n",
      "Epoch[495/500] loss_G : 200.607727 loss_D : -2.556775\n",
      "Epoch[496/500] loss_G : 201.135950 loss_D : -2.547961\n",
      "Epoch[497/500] loss_G : 201.350622 loss_D : -2.564261\n",
      "Epoch[498/500] loss_G : 201.523661 loss_D : -2.561805\n",
      "Epoch[499/500] loss_G : 202.110787 loss_D : -2.551918\n",
      "Epoch[500/500] loss_G : 202.104666 loss_D : -2.554289\n",
      "model saved to /data/allen/hw2model/sngangp_G_ep500.pth\n",
      "model saved to /data/allen/hw2model/sngangp_D_ep500.pth\n"
     ]
    }
   ],
   "source": [
    "SNGAN_GP.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
