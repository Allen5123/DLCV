{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"train_batchsz\" : 128,\n",
    "    \"epoch\" : 200,\n",
    "    \"lr\" : 1.0e-4,\n",
    "    \"betas\" : (0.5, 0.999),\n",
    "    \"train_path\" : '/data/dlcv/hw2/hw2_data/face/train/',\n",
    "    \"val_path\" : '/data/dlcv/hw2/hw2_data/face/val/',\n",
    "    \"G_path\" : '/data/allen/hw2model/dcgan_G.pth',\n",
    "    \"D_path\" :  '/data/allen/hw2model/dcgan_D.pth',\n",
    "    \"device\" :  \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"c_noise\" : 100,\n",
    "    \"feature_dim\" : 64\n",
    "}\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.set_device(7)\n",
    "print('Device used :', config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # Python built-in random module\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, dirpath, transform = None) -> None:\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        files = glob.glob(os.path.join(dirpath, \"*.png\"))\n",
    "        for file in files:\n",
    "            image = Image.open(file)\n",
    "            self.data.append(image)\n",
    "        self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, c_noise, feature_dim, c_img) -> None:\n",
    "        super().__init__()\n",
    "        self.project = nn.Sequential(\n",
    "            nn.ConvTranspose2d(c_noise, feature_dim*16, kernel_size=4, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_dim*16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            self.dconv_bn_relu(feature_dim*16, feature_dim*8),\n",
    "            self.dconv_bn_relu(feature_dim*8, feature_dim*4),\n",
    "            self.dconv_bn_relu(feature_dim*4, feature_dim*2)\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(feature_dim*2, c_img, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def dconv_bn_relu(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_dim, out_dim, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.project(x)\n",
    "        x2 = self.conv(x1)\n",
    "        # print(\"Generator x1 {} x2 {}\".format(x1.shape, x2.shape))\n",
    "        return self.last(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_dim, c_img) -> None:\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(c_img, feature_dim, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self.conv_bn_lrelu(feature_dim, feature_dim*2),\n",
    "            self.conv_bn_lrelu(feature_dim*2, feature_dim*4),\n",
    "            self.conv_bn_lrelu(feature_dim*4, feature_dim*8),\n",
    "            nn.Conv2d(feature_dim*8, 1, kernel_size=4, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def conv_bn_lrelu(self, in_dim, out_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x).squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGan():\n",
    "    def __init__(self, config) -> None:\n",
    "        self.config = config\n",
    "        self.G = Generator(self.config[\"c_noise\"], self.config[\"feature_dim\"], 3)\n",
    "        self.D = Discriminator(self.config[\"feature_dim\"], 3)\n",
    "\n",
    "        self.optimizer_G = optim.Adam(self.G.parameters(), lr=self.config[\"lr\"], betas=self.config[\"betas\"])\n",
    "        self.optimizer_D = optim.Adam(self.D.parameters(), lr=self.config[\"lr\"], betas=self.config[\"betas\"])\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        self.z_samples = torch.randn(32, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #fix sample used\n",
    "        \n",
    "    def CreateLoader(self):\n",
    "        self.train_loader = DataLoader(FaceDataset(dirpath=self.config[\"train_path\"], transform=train_tfm), batch_size=self.config[\"train_batchsz\"], shuffle=True, pin_memory=True)\n",
    "        self.refresh = len(self.train_loader.dataset) / self.config[\"train_batchsz\"]\n",
    "        print(len(self.train_loader.dataset))\n",
    "\n",
    "    def SaveEpochResult(self, ep):\n",
    "        self.G.eval()\n",
    "        imgs = self.G(self.z_samples).detach().cpu()\n",
    "        imgs = (imgs + 1.) / 2.0\n",
    "        torchvision.utils.save_image(imgs, fp=\"/data/allen/gangrid/dcgan_ep{}.png\".format(ep + 1), padding=0)\n",
    "\n",
    "    def train(self):\n",
    "        self.CreateLoader()\n",
    "        self.G = self.G.to(self.config[\"device\"])\n",
    "        self.D = self.D.to(self.config[\"device\"])\n",
    "        for ep in range(self.config[\"epoch\"]):\n",
    "            self.D.train()\n",
    "            self.G.train()\n",
    "            total_loss_D, total_loss_G = 0., 0.\n",
    "            for (idx, real_img) in enumerate(self.train_loader):\n",
    "                bsz = real_img.shape[0]\n",
    "                #train Discriminator\n",
    "                real_img = real_img.to(self.config[\"device\"]) #(bsz, 3, 64, 64)\n",
    "                real_label = torch.ones((bsz, ), device=self.config[\"device\"]) #(bsz, )\n",
    "                real_logit = self.D(real_img) #(bsz, )\n",
    "                # print(\"r_image {} r_label {} r_logit\".format(real_img.shape, real_label.shape, real_logit.shape))\n",
    "                real_loss = self.criterion(real_logit, real_label)\n",
    "                random_z = torch.randn(bsz, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #(bsz, 100, 1, 1)\n",
    "                fake_img = self.G(random_z) #(bsz, 3, 64, 64)\n",
    "                fake_label = torch.zeros((bsz, ), device=self.config[\"device\"]) #(bsz, )\n",
    "                fake_logit = self.D(fake_img) #(bsz, )\n",
    "                # print(\"f_image {} f_label {} f_logit\".format(fake_img.shape, fake_label.shape, fake_logit.shape))\n",
    "                fake_loss = self.criterion(fake_logit, fake_label)\n",
    "                loss_D = (real_loss + fake_loss) / 2\n",
    "                total_loss_D += loss_D.item()\n",
    "                # Discriminator backwarding\n",
    "                self.D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                #train Generater\n",
    "                random_z = torch.randn(bsz, self.config[\"c_noise\"], 1, 1, device=self.config[\"device\"]) #(bsz, 100, 1, 1)\n",
    "                fake_img = self.G(random_z)  #(bsz, 3, 64, 64)\n",
    "                fake_logit = self.D(fake_img) #(bsz, )\n",
    "                loss_G = self.criterion(fake_logit, real_label)\n",
    "                total_loss_G += loss_G.item()\n",
    "                # Generator backwarding\n",
    "                self.G.zero_grad()\n",
    "                loss_G.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "            self.SaveEpochResult(ep)\n",
    "            print(\"Epoch[{}/{}] loss_G : {:.6f} loss_D : {:.6f}\".format(ep + 1, self.config[\"epoch\"], total_loss_G / (self.refresh), total_loss_D / (self.refresh)))\n",
    "            if (ep + 1) % 100 == 0:\n",
    "                save_checkpoint(\"/data/allen/hw2model/dcgan_G_ep{}.pth\".format(ep + 1), self.G, self.optimizer_G)\n",
    "                save_checkpoint(\"/data/allen/hw2model/dcgan_D_ep{}.pth\".format(ep + 1), self.D, self.optimizer_D)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCGAN = TrainGan(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38464\n",
      "Epoch[1/200] loss_G : 6.680003 loss_D : 0.454092\n",
      "Epoch[2/200] loss_G : 3.352254 loss_D : 0.397286\n",
      "Epoch[3/200] loss_G : 3.180087 loss_D : 0.358949\n",
      "Epoch[4/200] loss_G : 3.074823 loss_D : 0.439574\n",
      "Epoch[5/200] loss_G : 3.498047 loss_D : 0.391640\n",
      "Epoch[6/200] loss_G : 3.329298 loss_D : 0.394997\n",
      "Epoch[7/200] loss_G : 3.035551 loss_D : 0.381383\n",
      "Epoch[8/200] loss_G : 2.944751 loss_D : 0.385395\n",
      "Epoch[9/200] loss_G : 3.007794 loss_D : 0.356832\n",
      "Epoch[10/200] loss_G : 2.798196 loss_D : 0.366431\n",
      "Epoch[11/200] loss_G : 2.652982 loss_D : 0.347175\n",
      "Epoch[12/200] loss_G : 2.597107 loss_D : 0.349507\n",
      "Epoch[13/200] loss_G : 2.521463 loss_D : 0.369286\n",
      "Epoch[14/200] loss_G : 2.615038 loss_D : 0.350668\n",
      "Epoch[15/200] loss_G : 2.528749 loss_D : 0.352190\n",
      "Epoch[16/200] loss_G : 2.500395 loss_D : 0.359663\n",
      "Epoch[17/200] loss_G : 2.463727 loss_D : 0.368085\n",
      "Epoch[18/200] loss_G : 2.377447 loss_D : 0.378761\n",
      "Epoch[19/200] loss_G : 2.390643 loss_D : 0.348742\n",
      "Epoch[20/200] loss_G : 2.330604 loss_D : 0.369489\n",
      "Epoch[21/200] loss_G : 2.334708 loss_D : 0.356826\n",
      "Epoch[22/200] loss_G : 2.271229 loss_D : 0.349086\n",
      "Epoch[23/200] loss_G : 2.348672 loss_D : 0.355426\n",
      "Epoch[24/200] loss_G : 2.425772 loss_D : 0.309775\n",
      "Epoch[25/200] loss_G : 2.436494 loss_D : 0.320728\n",
      "Epoch[26/200] loss_G : 2.524788 loss_D : 0.342820\n",
      "Epoch[27/200] loss_G : 2.460700 loss_D : 0.303701\n",
      "Epoch[28/200] loss_G : 2.450673 loss_D : 0.306289\n",
      "Epoch[29/200] loss_G : 2.518501 loss_D : 0.298935\n",
      "Epoch[30/200] loss_G : 2.512865 loss_D : 0.323782\n",
      "Epoch[31/200] loss_G : 2.535775 loss_D : 0.284054\n",
      "Epoch[32/200] loss_G : 2.588644 loss_D : 0.300848\n",
      "Epoch[33/200] loss_G : 2.560480 loss_D : 0.287730\n",
      "Epoch[34/200] loss_G : 2.587409 loss_D : 0.277906\n",
      "Epoch[35/200] loss_G : 2.606955 loss_D : 0.261731\n",
      "Epoch[36/200] loss_G : 2.611025 loss_D : 0.274583\n",
      "Epoch[37/200] loss_G : 2.676039 loss_D : 0.282646\n",
      "Epoch[38/200] loss_G : 2.567636 loss_D : 0.285708\n",
      "Epoch[39/200] loss_G : 2.729828 loss_D : 0.256522\n",
      "Epoch[40/200] loss_G : 2.594308 loss_D : 0.301790\n",
      "Epoch[41/200] loss_G : 2.680690 loss_D : 0.256936\n",
      "Epoch[42/200] loss_G : 2.727429 loss_D : 0.251398\n",
      "Epoch[43/200] loss_G : 2.690538 loss_D : 0.261843\n",
      "Epoch[44/200] loss_G : 2.738356 loss_D : 0.258537\n",
      "Epoch[45/200] loss_G : 2.718274 loss_D : 0.241396\n",
      "Epoch[46/200] loss_G : 2.751757 loss_D : 0.274655\n",
      "Epoch[47/200] loss_G : 2.757189 loss_D : 0.225596\n",
      "Epoch[48/200] loss_G : 2.776866 loss_D : 0.234480\n",
      "Epoch[49/200] loss_G : 2.737486 loss_D : 0.293462\n",
      "Epoch[50/200] loss_G : 2.713749 loss_D : 0.242535\n",
      "Epoch[51/200] loss_G : 2.746730 loss_D : 0.241258\n",
      "Epoch[52/200] loss_G : 2.806322 loss_D : 0.226674\n",
      "Epoch[53/200] loss_G : 2.831922 loss_D : 0.261248\n",
      "Epoch[54/200] loss_G : 2.717381 loss_D : 0.262785\n",
      "Epoch[55/200] loss_G : 2.803793 loss_D : 0.223939\n",
      "Epoch[56/200] loss_G : 2.835125 loss_D : 0.235700\n",
      "Epoch[57/200] loss_G : 2.700764 loss_D : 0.255696\n",
      "Epoch[58/200] loss_G : 2.835641 loss_D : 0.221722\n",
      "Epoch[59/200] loss_G : 2.849752 loss_D : 0.239919\n",
      "Epoch[60/200] loss_G : 2.842238 loss_D : 0.258829\n",
      "Epoch[61/200] loss_G : 2.853217 loss_D : 0.222253\n",
      "Epoch[62/200] loss_G : 2.796939 loss_D : 0.244488\n",
      "Epoch[63/200] loss_G : 2.858679 loss_D : 0.229221\n",
      "Epoch[64/200] loss_G : 2.870922 loss_D : 0.249700\n",
      "Epoch[65/200] loss_G : 2.905266 loss_D : 0.210391\n",
      "Epoch[66/200] loss_G : 2.905253 loss_D : 0.248325\n",
      "Epoch[67/200] loss_G : 2.884631 loss_D : 0.227097\n",
      "Epoch[68/200] loss_G : 2.920459 loss_D : 0.187853\n",
      "Epoch[69/200] loss_G : 2.920904 loss_D : 0.233472\n",
      "Epoch[70/200] loss_G : 2.879928 loss_D : 0.236188\n",
      "Epoch[71/200] loss_G : 2.927642 loss_D : 0.223382\n",
      "Epoch[72/200] loss_G : 2.816726 loss_D : 0.265228\n",
      "Epoch[73/200] loss_G : 2.933631 loss_D : 0.208491\n",
      "Epoch[74/200] loss_G : 2.951639 loss_D : 0.198546\n",
      "Epoch[75/200] loss_G : 2.932404 loss_D : 0.240160\n",
      "Epoch[76/200] loss_G : 2.918014 loss_D : 0.230837\n",
      "Epoch[77/200] loss_G : 2.991218 loss_D : 0.196325\n",
      "Epoch[78/200] loss_G : 2.999347 loss_D : 0.208675\n",
      "Epoch[79/200] loss_G : 2.930745 loss_D : 0.221726\n",
      "Epoch[80/200] loss_G : 2.927652 loss_D : 0.239523\n",
      "Epoch[81/200] loss_G : 3.062698 loss_D : 0.150482\n",
      "Epoch[82/200] loss_G : 2.926835 loss_D : 0.277211\n",
      "Epoch[83/200] loss_G : 2.968190 loss_D : 0.237787\n",
      "Epoch[84/200] loss_G : 3.014483 loss_D : 0.149113\n",
      "Epoch[85/200] loss_G : 2.873090 loss_D : 0.309310\n",
      "Epoch[86/200] loss_G : 2.841638 loss_D : 0.225571\n",
      "Epoch[87/200] loss_G : 2.916502 loss_D : 0.228908\n",
      "Epoch[88/200] loss_G : 3.034869 loss_D : 0.166197\n",
      "Epoch[89/200] loss_G : 3.049431 loss_D : 0.201064\n",
      "Epoch[90/200] loss_G : 3.046150 loss_D : 0.239558\n",
      "Epoch[91/200] loss_G : 3.090415 loss_D : 0.165652\n",
      "Epoch[92/200] loss_G : 3.040906 loss_D : 0.200283\n",
      "Epoch[93/200] loss_G : 2.991009 loss_D : 0.233349\n",
      "Epoch[94/200] loss_G : 3.088827 loss_D : 0.169622\n",
      "Epoch[95/200] loss_G : 2.783095 loss_D : 0.305885\n",
      "Epoch[96/200] loss_G : 3.097036 loss_D : 0.194305\n",
      "Epoch[97/200] loss_G : 3.091407 loss_D : 0.175825\n",
      "Epoch[98/200] loss_G : 3.220593 loss_D : 0.176241\n",
      "Epoch[99/200] loss_G : 3.079123 loss_D : 0.225826\n",
      "Epoch[100/200] loss_G : 3.093712 loss_D : 0.183111\n",
      "model saved to /data/allen/hw2model/dcgan_G_ep100.pth\n",
      "model saved to /data/allen/hw2model/dcgan_D_ep100.pth\n",
      "Epoch[101/200] loss_G : 3.084454 loss_D : 0.200846\n",
      "Epoch[102/200] loss_G : 3.068897 loss_D : 0.218460\n",
      "Epoch[103/200] loss_G : 3.126543 loss_D : 0.192545\n",
      "Epoch[104/200] loss_G : 3.153233 loss_D : 0.184610\n",
      "Epoch[105/200] loss_G : 3.164481 loss_D : 0.162767\n",
      "Epoch[106/200] loss_G : 3.011185 loss_D : 0.235312\n",
      "Epoch[107/200] loss_G : 3.190450 loss_D : 0.170190\n",
      "Epoch[108/200] loss_G : 3.180641 loss_D : 0.182224\n",
      "Epoch[109/200] loss_G : 3.191616 loss_D : 0.198632\n",
      "Epoch[110/200] loss_G : 3.288670 loss_D : 0.145238\n",
      "Epoch[111/200] loss_G : 3.217301 loss_D : 0.190498\n",
      "Epoch[112/200] loss_G : 3.267309 loss_D : 0.185701\n",
      "Epoch[113/200] loss_G : 3.299971 loss_D : 0.143609\n",
      "Epoch[114/200] loss_G : 3.200708 loss_D : 0.224676\n",
      "Epoch[115/200] loss_G : 3.305291 loss_D : 0.133492\n",
      "Epoch[116/200] loss_G : 3.159048 loss_D : 0.238936\n",
      "Epoch[117/200] loss_G : 3.347883 loss_D : 0.131790\n",
      "Epoch[118/200] loss_G : 3.251375 loss_D : 0.201922\n",
      "Epoch[119/200] loss_G : 3.346485 loss_D : 0.133853\n",
      "Epoch[120/200] loss_G : 3.397269 loss_D : 0.153937\n",
      "Epoch[121/200] loss_G : 3.241188 loss_D : 0.222577\n",
      "Epoch[122/200] loss_G : 3.347673 loss_D : 0.140149\n",
      "Epoch[123/200] loss_G : 3.169480 loss_D : 0.244958\n",
      "Epoch[124/200] loss_G : 3.261750 loss_D : 0.165125\n",
      "Epoch[125/200] loss_G : 3.445746 loss_D : 0.129414\n",
      "Epoch[126/200] loss_G : 3.323579 loss_D : 0.189752\n",
      "Epoch[127/200] loss_G : 3.339102 loss_D : 0.187094\n",
      "Epoch[128/200] loss_G : 3.463576 loss_D : 0.114497\n",
      "Epoch[129/200] loss_G : 3.403189 loss_D : 0.197626\n",
      "Epoch[130/200] loss_G : 3.327377 loss_D : 0.173574\n",
      "Epoch[131/200] loss_G : 3.490638 loss_D : 0.132599\n",
      "Epoch[132/200] loss_G : 3.475918 loss_D : 0.141771\n",
      "Epoch[133/200] loss_G : 3.437475 loss_D : 0.155888\n",
      "Epoch[134/200] loss_G : 3.442611 loss_D : 0.192904\n",
      "Epoch[135/200] loss_G : 3.465592 loss_D : 0.135944\n",
      "Epoch[136/200] loss_G : 3.489043 loss_D : 0.152617\n",
      "Epoch[137/200] loss_G : 3.584222 loss_D : 0.116930\n",
      "Epoch[138/200] loss_G : 3.276017 loss_D : 0.243006\n",
      "Epoch[139/200] loss_G : 3.510049 loss_D : 0.132210\n",
      "Epoch[140/200] loss_G : 3.538933 loss_D : 0.158040\n",
      "Epoch[141/200] loss_G : 3.532517 loss_D : 0.134104\n",
      "Epoch[142/200] loss_G : 3.651940 loss_D : 0.131619\n",
      "Epoch[143/200] loss_G : 3.695639 loss_D : 0.099207\n",
      "Epoch[144/200] loss_G : 3.504315 loss_D : 0.185730\n",
      "Epoch[145/200] loss_G : 3.514421 loss_D : 0.170774\n",
      "Epoch[146/200] loss_G : 3.736106 loss_D : 0.111649\n",
      "Epoch[147/200] loss_G : 3.614556 loss_D : 0.116682\n",
      "Epoch[148/200] loss_G : 3.206827 loss_D : 0.274145\n",
      "Epoch[149/200] loss_G : 3.601463 loss_D : 0.118221\n",
      "Epoch[150/200] loss_G : 3.595212 loss_D : 0.154224\n",
      "Epoch[151/200] loss_G : 3.629763 loss_D : 0.149403\n",
      "Epoch[152/200] loss_G : 3.646561 loss_D : 0.128845\n",
      "Epoch[153/200] loss_G : 3.312260 loss_D : 0.242486\n",
      "Epoch[154/200] loss_G : 3.531046 loss_D : 0.158482\n",
      "Epoch[155/200] loss_G : 3.774056 loss_D : 0.093514\n",
      "Epoch[156/200] loss_G : 3.722595 loss_D : 0.164139\n",
      "Epoch[157/200] loss_G : 3.557058 loss_D : 0.160188\n",
      "Epoch[158/200] loss_G : 3.750140 loss_D : 0.097448\n",
      "Epoch[159/200] loss_G : 3.511848 loss_D : 0.195475\n",
      "Epoch[160/200] loss_G : 3.724143 loss_D : 0.095134\n",
      "Epoch[161/200] loss_G : 3.773034 loss_D : 0.123475\n",
      "Epoch[162/200] loss_G : 3.758222 loss_D : 0.130212\n",
      "Epoch[163/200] loss_G : 3.643170 loss_D : 0.171049\n",
      "Epoch[164/200] loss_G : 3.833992 loss_D : 0.092739\n",
      "Epoch[165/200] loss_G : 3.817774 loss_D : 0.123958\n",
      "Epoch[166/200] loss_G : 3.658547 loss_D : 0.195032\n",
      "Epoch[167/200] loss_G : 3.789175 loss_D : 0.086693\n",
      "Epoch[168/200] loss_G : 3.734101 loss_D : 0.134093\n",
      "Epoch[169/200] loss_G : 3.642602 loss_D : 0.182863\n",
      "Epoch[170/200] loss_G : 3.890353 loss_D : 0.074689\n",
      "Epoch[171/200] loss_G : 3.926896 loss_D : 0.102251\n",
      "Epoch[172/200] loss_G : 3.830134 loss_D : 0.140253\n",
      "Epoch[173/200] loss_G : 3.728724 loss_D : 0.168581\n",
      "Epoch[174/200] loss_G : 3.935043 loss_D : 0.093256\n",
      "Epoch[175/200] loss_G : 3.902080 loss_D : 0.102921\n",
      "Epoch[176/200] loss_G : 3.682439 loss_D : 0.228242\n",
      "Epoch[177/200] loss_G : 3.734551 loss_D : 0.121275\n",
      "Epoch[178/200] loss_G : 4.006515 loss_D : 0.074557\n",
      "Epoch[179/200] loss_G : 3.929679 loss_D : 0.130124\n",
      "Epoch[180/200] loss_G : 3.967383 loss_D : 0.101788\n",
      "Epoch[181/200] loss_G : 3.898625 loss_D : 0.128356\n",
      "Epoch[182/200] loss_G : 3.899139 loss_D : 0.130325\n",
      "Epoch[183/200] loss_G : 4.078145 loss_D : 0.075205\n",
      "Epoch[184/200] loss_G : 3.824142 loss_D : 0.157397\n",
      "Epoch[185/200] loss_G : 4.030776 loss_D : 0.094457\n",
      "Epoch[186/200] loss_G : 3.866776 loss_D : 0.143931\n",
      "Epoch[187/200] loss_G : 4.145201 loss_D : 0.073814\n",
      "Epoch[188/200] loss_G : 3.873190 loss_D : 0.227848\n",
      "Epoch[189/200] loss_G : 3.895736 loss_D : 0.088976\n",
      "Epoch[190/200] loss_G : 3.856820 loss_D : 0.167848\n",
      "Epoch[191/200] loss_G : 3.970963 loss_D : 0.086599\n",
      "Epoch[192/200] loss_G : 4.095318 loss_D : 0.075254\n",
      "Epoch[193/200] loss_G : 3.950556 loss_D : 0.140899\n",
      "Epoch[194/200] loss_G : 4.260340 loss_D : 0.059232\n",
      "Epoch[195/200] loss_G : 3.881566 loss_D : 0.178123\n",
      "Epoch[196/200] loss_G : 4.032952 loss_D : 0.105211\n",
      "Epoch[197/200] loss_G : 3.902444 loss_D : 0.169436\n",
      "Epoch[198/200] loss_G : 4.099179 loss_D : 0.067052\n",
      "Epoch[199/200] loss_G : 4.218495 loss_D : 0.093489\n",
      "Epoch[200/200] loss_G : 4.138448 loss_D : 0.082547\n",
      "model saved to /data/allen/hw2model/dcgan_G_ep200.pth\n",
      "model saved to /data/allen/hw2model/dcgan_D_ep200.pth\n"
     ]
    }
   ],
   "source": [
    "DCGAN.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
