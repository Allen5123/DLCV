{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'train_pth':'/data/dlcv/hw4/office/train/',\n",
    "    'val_pth':'/data/dlcv/hw4/office/val/',\n",
    "    'train_csv_pth':'/data/dlcv/hw4/office/train.csv',\n",
    "    'val_csv_pth':'/data/dlcv/hw4/office/val.csv',\n",
    "    'save_pth':'/data/allen/hw4model/setting_b.pth',\n",
    "    'backbone_pth':'/data/dlcv/hw4/pretrain_model_SL.pt',\n",
    "    'bsz':32,\n",
    "    'lr':1.e-3,\n",
    "    'epochs':200,\n",
    "    'imgsz':128,\n",
    "    'numofclass':65\n",
    "}\n",
    "backbone_transform = transforms.Compose([\n",
    "    transforms.Resize((config['imgsz'], config['imgsz'])),\n",
    "    transforms.CenterCrop(config['imgsz']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225]))\n",
    "])\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.set_device(6)\n",
    "print('Device used :', config['device'])\n",
    "label2class = {'Alarm_Clock': 0, 'Backpack': 1, 'Batteries': 2, 'Bed': 3, 'Bike': 4, 'Bottle': 5, 'Bucket': 6, 'Calculator': 7, 'Calendar': 8, 'Candles': 9, 'Chair': 10, 'Clipboards': 11, 'Computer': 12, \n",
    "    'Couch': 13, 'Curtains': 14, 'Desk_Lamp': 15, 'Drill': 16, 'Eraser': 17, 'Exit_Sign': 18, 'Fan': 19, 'File_Cabinet': 20, 'Flipflops': 21, 'Flowers': 22, 'Folder': 23, 'Fork': 24, 'Glasses': 25,\n",
    "    'Hammer': 26, 'Helmet': 27, 'Kettle': 28, 'Keyboard': 29, 'Knives': 30, 'Lamp_Shade': 31, 'Laptop': 32, 'Marker': 33, 'Monitor': 34, 'Mop': 35, 'Mouse': 36, 'Mug': 37, 'Notebook': 38,\n",
    "    'Oven': 39, 'Pan': 40, 'Paper_Clip': 41, 'Pen': 42, 'Pencil': 43, 'Postit_Notes': 44, 'Printer': 45, 'Push_Pin': 46, 'Radio': 47, 'Refrigerator': 48, 'Ruler': 49, 'Scissors': 50, 'Screwdriver': 51,\n",
    "    'Shelf': 52, 'Sink': 53, 'Sneakers': 54, 'Soda': 55, 'Speaker': 56, 'Spoon': 57, 'TV': 58, 'Table': 59, 'Telephone': 60, 'ToothBrush': 61, 'Toys': 62, 'Trash_Can': 63, 'Webcam': 64}\n",
    "class2label = {0: 'Alarm_Clock', 1: 'Backpack', 2: 'Batteries', 3: 'Bed', 4: 'Bike', 5: 'Bottle', 6: 'Bucket', 7: 'Calculator', 8: 'Calendar', 9: 'Candles', 10: 'Chair', 11: 'Clipboards', 12: 'Computer', \n",
    "    13: 'Couch', 14: 'Curtains', 15: 'Desk_Lamp', 16: 'Drill', 17: 'Eraser', 18: 'Exit_Sign', 19: 'Fan', 20: 'File_Cabinet', 21: 'Flipflops', 22: 'Flowers', 23: 'Folder', 24: 'Fork', 25: 'Glasses', \n",
    "    26: 'Hammer', 27: 'Helmet', 28: 'Kettle', 29: 'Keyboard', 30: 'Knives', 31: 'Lamp_Shade', 32: 'Laptop', 33: 'Marker', 34: 'Monitor', 35: 'Mop', 36: 'Mouse', 37: 'Mug', 38: 'Notebook', \n",
    "    39: 'Oven', 40: 'Pan', 41: 'Paper_Clip', 42: 'Pen', 43: 'Pencil', 44: 'Postit_Notes', 45: 'Printer', 46: 'Push_Pin', 47: 'Radio', 48: 'Refrigerator', 49: 'Ruler', 50: 'Scissors', 51: 'Screwdriver', \n",
    "    52: 'Shelf', 53: 'Sink', 54: 'Sneakers', 55: 'Soda', 56: 'Speaker', 57: 'Spoon', 58: 'TV', 59: 'Table', 60: 'Telephone', 61: 'ToothBrush', 62: 'Toys', 63: 'Trash_Can', 64: 'Webcam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, device='cpu'):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    return checkpoint[\"model_state_dict\"], checkpoint[\"optimizer_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, datapath, csvpath, transform=None) -> None:\n",
    "        self.transform = transform\n",
    "        self.data = [] #(imgpath, imgname, #label)\n",
    "        if csvpath is not None:\n",
    "            if os.path.exists(csvpath):\n",
    "                df = pd.read_csv(csvpath)\n",
    "                self.data = [(os.path.join(datapath, name), name, label2class[label]) for name, label in zip(df['filename'], df['label'])]\n",
    "            else:\n",
    "                print(f\"Can't find {csvpath}\")\n",
    "                exit(-1)\n",
    "        else:\n",
    "            if os.path.exists(datapath):\n",
    "                paths = glob.glob(os.path.join(datapath, \"*\"))\n",
    "                for path in paths:\n",
    "                    imgname = os.path.split(path)[-1]\n",
    "                    self.data.append((path, imgname, None))\n",
    "            else:\n",
    "                print(f\"Can't open {datapath}\")\n",
    "                exit(-1)\n",
    "        self.len = len(self.data)\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgpath, imgname, label = self.data[index]\n",
    "        img = Image.open(imgpath)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label if label is not None else img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951\n",
      "406\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(DS(config['train_pth'], config['train_csv_pth'], transform=backbone_transform), batch_size=config['bsz'], shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(DS(config['val_pth'], config['val_csv_pth'], transform=backbone_transform), batch_size=config['bsz'], pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildLabelDict(train_csv):\n",
    "    label2class, class2label = {}, {}\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    labellist = sorted(list(dict.fromkeys([name for name in train_df['label']])))\n",
    "    label2class = {label : idx for (idx, label) in enumerate(labellist)}\n",
    "    class2label = {idx : label for (idx, label) in enumerate(labellist)}\n",
    "    print(label2class, class2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierB(nn.Module):\n",
    "    def __init__(self, backbone_pth) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=None)\n",
    "        self.backbone.load_state_dict(torch.load(backbone_pth, map_location=config['device']))\n",
    "        self.classifier = nn.Linear(1000, config['numofclass'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.backbone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierB(config['backbone_pth']).to(config['device'])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [1/200] train_loss : 3.4508370771640684 train_acc : 16.38% val_loss : 3.335188150405884 val_acc : 22.91%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [2/200] train_loss : 2.460565923675289 train_acc : 34.30% val_loss : 3.3525496323903403 val_acc : 27.83%\n",
      "Epoch [3/200] train_loss : 1.4713064674439469 train_acc : 58.26% val_loss : 3.8562464515368142 val_acc : 24.88%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [4/200] train_loss : 0.7197144030313182 train_acc : 78.99% val_loss : 5.010620931784312 val_acc : 30.54%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [5/200] train_loss : 0.42438012930920455 train_acc : 87.45% val_loss : 4.39584465821584 val_acc : 30.79%\n",
      "Epoch [6/200] train_loss : 0.24888869515824608 train_acc : 93.12% val_loss : 5.21098130941391 val_acc : 28.82%\n",
      "Epoch [7/200] train_loss : 0.2548530919522774 train_acc : 92.41% val_loss : 5.356104572614034 val_acc : 28.82%\n",
      "Epoch [8/200] train_loss : 0.21566765332912527 train_acc : 94.03% val_loss : 5.278454085191091 val_acc : 29.31%\n",
      "Epoch [9/200] train_loss : 0.2569262995346775 train_acc : 91.93% val_loss : 5.519037246704102 val_acc : 27.59%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [10/200] train_loss : 0.24526342449755204 train_acc : 93.14% val_loss : 4.923353433609009 val_acc : 31.53%\n",
      "Epoch [11/200] train_loss : 0.16016253978165426 train_acc : 95.57% val_loss : 4.98021525144577 val_acc : 29.06%\n",
      "Epoch [12/200] train_loss : 0.07493870318166881 train_acc : 98.20% val_loss : 5.765263696511586 val_acc : 27.83%\n",
      "Epoch [13/200] train_loss : 0.11239126449681788 train_acc : 96.96% val_loss : 5.626530110836029 val_acc : 27.34%\n",
      "Epoch [14/200] train_loss : 0.12102396071063189 train_acc : 96.51% val_loss : 6.556008577346802 val_acc : 25.86%\n",
      "Epoch [15/200] train_loss : 0.20063865353633475 train_acc : 94.18% val_loss : 5.245671192804973 val_acc : 24.63%\n",
      "Epoch [16/200] train_loss : 0.17999543659237585 train_acc : 94.58% val_loss : 5.6217376589775085 val_acc : 29.31%\n",
      "Epoch [17/200] train_loss : 0.14389451755195615 train_acc : 95.67% val_loss : 5.59855180978775 val_acc : 30.05%\n",
      "Epoch [18/200] train_loss : 0.09875955767323816 train_acc : 96.86% val_loss : 6.541502078374227 val_acc : 25.62%\n",
      "Epoch [19/200] train_loss : 0.17393256603868876 train_acc : 94.58% val_loss : 6.022336681683858 val_acc : 27.34%\n",
      "Epoch [20/200] train_loss : 0.1874996048087875 train_acc : 94.20% val_loss : 5.68187141418457 val_acc : 30.05%\n",
      "Epoch [21/200] train_loss : 0.12645352831890247 train_acc : 96.10% val_loss : 6.06520954767863 val_acc : 29.31%\n",
      "Epoch [22/200] train_loss : 0.1426211680499534 train_acc : 95.62% val_loss : 5.998081624507904 val_acc : 28.82%\n",
      "Epoch [23/200] train_loss : 0.10129216497922998 train_acc : 96.74% val_loss : 6.686924656232198 val_acc : 27.59%\n",
      "Epoch [24/200] train_loss : 0.08888993042566609 train_acc : 97.62% val_loss : 6.359381854534149 val_acc : 28.57%\n",
      "Epoch [25/200] train_loss : 0.09930943920299774 train_acc : 96.94% val_loss : 6.372346639633179 val_acc : 28.08%\n",
      "Epoch [26/200] train_loss : 0.11099195966830219 train_acc : 96.91% val_loss : 5.929589748382568 val_acc : 26.60%\n",
      "Epoch [27/200] train_loss : 0.10844701395144807 train_acc : 96.46% val_loss : 7.296393314997355 val_acc : 24.38%\n",
      "Epoch [28/200] train_loss : 0.1321363069729433 train_acc : 95.87% val_loss : 6.616986632347107 val_acc : 25.12%\n",
      "Epoch [29/200] train_loss : 0.13019111827990737 train_acc : 96.23% val_loss : 5.937003672122955 val_acc : 29.31%\n",
      "Epoch [30/200] train_loss : 0.08051443346908574 train_acc : 97.27% val_loss : 6.091604828834534 val_acc : 30.79%\n",
      "Epoch [31/200] train_loss : 0.13902996003824641 train_acc : 95.85% val_loss : 6.096873958905538 val_acc : 27.83%\n",
      "Epoch [32/200] train_loss : 0.08532717325289287 train_acc : 97.34% val_loss : 6.207071125507355 val_acc : 30.79%\n",
      "Epoch [33/200] train_loss : 0.07361806925988143 train_acc : 97.65% val_loss : 6.828248580296834 val_acc : 26.85%\n",
      "Epoch [34/200] train_loss : 0.11728392338012988 train_acc : 96.81% val_loss : 6.765107154846191 val_acc : 29.56%\n",
      "Epoch [35/200] train_loss : 0.10325103065347284 train_acc : 96.79% val_loss : 7.302186806996663 val_acc : 27.83%\n",
      "Epoch [36/200] train_loss : 0.09166369433382268 train_acc : 97.42% val_loss : 6.517616430918376 val_acc : 28.82%\n",
      "Epoch [37/200] train_loss : 0.10481842437369097 train_acc : 96.53% val_loss : 7.478362997372945 val_acc : 24.14%\n",
      "Epoch [38/200] train_loss : 0.1126397115715999 train_acc : 96.79% val_loss : 6.9998311797777815 val_acc : 28.33%\n",
      "Epoch [39/200] train_loss : 0.10590764534057731 train_acc : 96.61% val_loss : 6.6247212290763855 val_acc : 27.59%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [40/200] train_loss : 0.07291725647259065 train_acc : 97.60% val_loss : 6.307616392771403 val_acc : 31.77%\n",
      "Epoch [41/200] train_loss : 0.06959607355803918 train_acc : 97.70% val_loss : 7.180261333783467 val_acc : 28.57%\n",
      "Epoch [42/200] train_loss : 0.07404696583824527 train_acc : 97.85% val_loss : 7.090739528338115 val_acc : 26.60%\n",
      "Epoch [43/200] train_loss : 0.09702692121410235 train_acc : 97.14% val_loss : 6.307462692260742 val_acc : 30.54%\n",
      "Epoch [44/200] train_loss : 0.060857983443287876 train_acc : 98.05% val_loss : 6.614904125531514 val_acc : 29.31%\n",
      "Epoch [45/200] train_loss : 0.08506502802019969 train_acc : 97.34% val_loss : 7.021302183469136 val_acc : 29.06%\n",
      "Epoch [46/200] train_loss : 0.13874965714152554 train_acc : 95.55% val_loss : 6.894139548142751 val_acc : 27.34%\n",
      "Epoch [47/200] train_loss : 0.11333748676655132 train_acc : 96.61% val_loss : 7.048794289429982 val_acc : 29.56%\n",
      "Epoch [48/200] train_loss : 0.1433893311579477 train_acc : 95.62% val_loss : 6.633540431658427 val_acc : 29.80%\n",
      "Epoch [49/200] train_loss : 0.10510789947508554 train_acc : 96.61% val_loss : 6.990512410799663 val_acc : 28.08%\n",
      "Epoch [50/200] train_loss : 0.09332862076429059 train_acc : 97.24% val_loss : 6.311654726664226 val_acc : 31.77%\n",
      "Epoch [51/200] train_loss : 0.07530269082905384 train_acc : 97.67% val_loss : 6.6253741184870405 val_acc : 29.31%\n",
      "Epoch [52/200] train_loss : 0.0660934463716907 train_acc : 97.75% val_loss : 7.427311182022095 val_acc : 28.82%\n",
      "Epoch [53/200] train_loss : 0.05068472325527966 train_acc : 98.46% val_loss : 7.005921343962352 val_acc : 30.79%\n",
      "Epoch [54/200] train_loss : 0.07751833624466761 train_acc : 97.82% val_loss : 6.08315642674764 val_acc : 28.82%\n",
      "Epoch [55/200] train_loss : 0.05366220459322127 train_acc : 98.30% val_loss : 6.384981671969096 val_acc : 29.56%\n",
      "Epoch [56/200] train_loss : 0.06970867088629591 train_acc : 97.75% val_loss : 7.541426698366801 val_acc : 26.85%\n",
      "Epoch [57/200] train_loss : 0.10539080209961933 train_acc : 96.79% val_loss : 7.273701032002767 val_acc : 26.11%\n",
      "Epoch [58/200] train_loss : 0.11105035712546858 train_acc : 96.58% val_loss : 6.120211640993754 val_acc : 29.31%\n",
      "Epoch [59/200] train_loss : 0.0954511475018642 train_acc : 96.86% val_loss : 7.008888324101766 val_acc : 28.57%\n",
      "Epoch [60/200] train_loss : 0.06793102668740264 train_acc : 98.05% val_loss : 6.443040907382965 val_acc : 28.82%\n",
      "Epoch [61/200] train_loss : 0.066975064043285 train_acc : 97.95% val_loss : 7.434488534927368 val_acc : 26.60%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [62/200] train_loss : 0.1045860213367647 train_acc : 97.04% val_loss : 6.72500063975652 val_acc : 32.51%\n",
      "Epoch [63/200] train_loss : 0.06627327654031824 train_acc : 98.00% val_loss : 6.9878475467364 val_acc : 32.51%\n",
      "Epoch [64/200] train_loss : 0.030216264396497026 train_acc : 98.79% val_loss : 7.246393243471782 val_acc : 31.77%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [65/200] train_loss : 0.039883536088781535 train_acc : 98.73% val_loss : 6.9678367376327515 val_acc : 34.48%\n",
      "Epoch [66/200] train_loss : 0.04816080709648171 train_acc : 98.25% val_loss : 7.208211700121562 val_acc : 30.79%\n",
      "Epoch [67/200] train_loss : 0.06192469439435915 train_acc : 98.00% val_loss : 7.276254614194234 val_acc : 26.60%\n",
      "Epoch [68/200] train_loss : 0.07709991470489432 train_acc : 97.72% val_loss : 8.25541067123413 val_acc : 25.37%\n",
      "Epoch [69/200] train_loss : 0.0752594574677334 train_acc : 97.72% val_loss : 7.059318204720815 val_acc : 31.03%\n",
      "Epoch [70/200] train_loss : 0.0920157046897864 train_acc : 97.39% val_loss : 7.135463158289592 val_acc : 28.33%\n",
      "Epoch [71/200] train_loss : 0.11208978985986158 train_acc : 96.89% val_loss : 7.5179981390635175 val_acc : 26.60%\n",
      "Epoch [72/200] train_loss : 0.07392608591772301 train_acc : 97.65% val_loss : 6.880987743536632 val_acc : 33.25%\n",
      "Epoch [73/200] train_loss : 0.038996024663007355 train_acc : 98.56% val_loss : 8.001729210217794 val_acc : 32.76%\n",
      "Epoch [74/200] train_loss : 0.04903756747447235 train_acc : 98.43% val_loss : 7.67202889919281 val_acc : 30.79%\n",
      "Epoch [75/200] train_loss : 0.06921990881475233 train_acc : 98.03% val_loss : 7.239313801129659 val_acc : 29.06%\n",
      "Epoch [76/200] train_loss : 0.08835335711717754 train_acc : 97.39% val_loss : 7.572255690892537 val_acc : 28.57%\n",
      "Epoch [77/200] train_loss : 0.0784460424255803 train_acc : 97.39% val_loss : 7.338976263999939 val_acc : 29.80%\n",
      "Epoch [78/200] train_loss : 0.06870357797559676 train_acc : 97.80% val_loss : 8.708575427532196 val_acc : 27.59%\n",
      "Epoch [79/200] train_loss : 0.06460250015116777 train_acc : 97.87% val_loss : 7.158502419789632 val_acc : 31.77%\n",
      "Epoch [80/200] train_loss : 0.03594955106636621 train_acc : 98.71% val_loss : 7.980317036310832 val_acc : 31.03%\n",
      "Epoch [81/200] train_loss : 0.048093227306597375 train_acc : 98.51% val_loss : 7.508946339289348 val_acc : 31.77%\n",
      "Epoch [82/200] train_loss : 0.02651021272086519 train_acc : 98.91% val_loss : 7.388441304365794 val_acc : 34.24%\n",
      "Epoch [83/200] train_loss : 0.042099347767953446 train_acc : 98.68% val_loss : 7.927036007245381 val_acc : 31.77%\n",
      "Epoch [84/200] train_loss : 0.05802593943709821 train_acc : 97.98% val_loss : 7.883864800135295 val_acc : 30.30%\n",
      "Epoch [85/200] train_loss : 0.1323551075060746 train_acc : 96.10% val_loss : 6.178483227888743 val_acc : 29.56%\n",
      "Epoch [86/200] train_loss : 0.10613635840576816 train_acc : 96.66% val_loss : 7.352081974347432 val_acc : 30.05%\n",
      "Epoch [87/200] train_loss : 0.04905542428618568 train_acc : 98.18% val_loss : 8.47652292251587 val_acc : 27.59%\n",
      "Epoch [88/200] train_loss : 0.08129169524181634 train_acc : 97.65% val_loss : 7.7236422300338745 val_acc : 29.31%\n",
      "Epoch [89/200] train_loss : 0.059961731405076914 train_acc : 97.98% val_loss : 7.771251320838928 val_acc : 32.51%\n",
      "Epoch [90/200] train_loss : 0.05265047540959175 train_acc : 98.13% val_loss : 7.474465171496074 val_acc : 32.51%\n",
      "Epoch [91/200] train_loss : 0.03139605538689192 train_acc : 98.86% val_loss : 8.40236779054006 val_acc : 30.54%\n",
      "Epoch [92/200] train_loss : 0.04604191299245955 train_acc : 98.20% val_loss : 7.68624476591746 val_acc : 32.51%\n",
      "Epoch [93/200] train_loss : 0.06615905580329719 train_acc : 97.95% val_loss : 7.319827159245809 val_acc : 30.30%\n",
      "Epoch [94/200] train_loss : 0.047430253580993544 train_acc : 98.43% val_loss : 8.579041202863058 val_acc : 28.08%\n",
      "Epoch [95/200] train_loss : 0.03221325808735634 train_acc : 98.66% val_loss : 7.506460428237915 val_acc : 33.50%\n",
      "Epoch [96/200] train_loss : 0.031242615140673308 train_acc : 99.09% val_loss : 7.06080820163091 val_acc : 31.28%\n",
      "Epoch [97/200] train_loss : 0.05945561362247785 train_acc : 98.13% val_loss : 6.680798411369324 val_acc : 29.56%\n",
      "Epoch [98/200] train_loss : 0.03960221259820365 train_acc : 98.63% val_loss : 7.379150112469991 val_acc : 31.53%\n",
      "Epoch [99/200] train_loss : 0.06464162238960379 train_acc : 97.82% val_loss : 7.331015845139821 val_acc : 29.80%\n",
      "Epoch [100/200] train_loss : 0.09876739245941635 train_acc : 97.54% val_loss : 7.355862359205882 val_acc : 28.82%\n",
      "Epoch [101/200] train_loss : 0.08381448277912094 train_acc : 97.44% val_loss : 7.771679719289144 val_acc : 28.08%\n",
      "Epoch [102/200] train_loss : 0.05419631672945494 train_acc : 98.15% val_loss : 7.034868359565735 val_acc : 30.79%\n",
      "Epoch [103/200] train_loss : 0.03049164538588673 train_acc : 98.84% val_loss : 7.327142715454102 val_acc : 33.25%\n",
      "Epoch [104/200] train_loss : 0.02175501336272631 train_acc : 98.99% val_loss : 6.873292605082194 val_acc : 32.51%\n",
      "Epoch [105/200] train_loss : 0.02779149745991133 train_acc : 98.89% val_loss : 7.840493480364482 val_acc : 31.77%\n",
      "Epoch [106/200] train_loss : 0.04273025158438874 train_acc : 98.73% val_loss : 8.46281894048055 val_acc : 29.56%\n",
      "Epoch [107/200] train_loss : 0.10619425782363585 train_acc : 97.17% val_loss : 7.95676851272583 val_acc : 26.11%\n",
      "Epoch [108/200] train_loss : 0.12307946952873826 train_acc : 96.63% val_loss : 6.975698630015056 val_acc : 29.80%\n",
      "Epoch [109/200] train_loss : 0.05659310287746035 train_acc : 97.90% val_loss : 8.381309449672699 val_acc : 29.31%\n",
      "Epoch [110/200] train_loss : 0.061787800209658156 train_acc : 98.20% val_loss : 7.0040204127629595 val_acc : 31.77%\n",
      "Epoch [111/200] train_loss : 0.05262458447399015 train_acc : 98.25% val_loss : 6.776617864767711 val_acc : 30.79%\n",
      "Epoch [112/200] train_loss : 0.07394048948038297 train_acc : 97.67% val_loss : 8.578048626581827 val_acc : 30.05%\n",
      "Epoch [113/200] train_loss : 0.04440002800196438 train_acc : 98.33% val_loss : 8.711071769396463 val_acc : 32.27%\n",
      "Epoch [114/200] train_loss : 0.054303364983567685 train_acc : 98.43% val_loss : 6.763663490613301 val_acc : 31.28%\n",
      "Epoch [115/200] train_loss : 0.024521824444986774 train_acc : 98.99% val_loss : 7.426926394303639 val_acc : 32.51%\n",
      "Epoch [116/200] train_loss : 0.03681320641601452 train_acc : 98.61% val_loss : 9.353763818740845 val_acc : 29.56%\n",
      "Epoch [117/200] train_loss : 0.04869449504876388 train_acc : 98.41% val_loss : 8.578855156898499 val_acc : 28.57%\n",
      "Epoch [118/200] train_loss : 0.06266777998707693 train_acc : 98.20% val_loss : 7.492406447728475 val_acc : 29.31%\n",
      "Epoch [119/200] train_loss : 0.03412708193937812 train_acc : 98.51% val_loss : 8.52774484952291 val_acc : 32.02%\n",
      "Epoch [120/200] train_loss : 0.07077995542618086 train_acc : 97.70% val_loss : 8.128680070241293 val_acc : 31.28%\n",
      "Epoch [121/200] train_loss : 0.05192498485986676 train_acc : 98.41% val_loss : 8.136394739151001 val_acc : 26.35%\n",
      "Epoch [122/200] train_loss : 0.07975146560115755 train_acc : 97.39% val_loss : 8.534674723943075 val_acc : 27.09%\n",
      "Epoch [123/200] train_loss : 0.06171994069373477 train_acc : 98.13% val_loss : 7.57365870475769 val_acc : 27.59%\n",
      "Epoch [124/200] train_loss : 0.045400239094749675 train_acc : 98.56% val_loss : 8.757178942362467 val_acc : 27.83%\n",
      "Epoch [125/200] train_loss : 0.04508463086696009 train_acc : 98.53% val_loss : 7.192594726880391 val_acc : 33.99%\n",
      "Epoch [126/200] train_loss : 0.03996515372574965 train_acc : 98.68% val_loss : 7.9922183354695635 val_acc : 29.80%\n",
      "Epoch [127/200] train_loss : 0.015435655790349664 train_acc : 99.32% val_loss : 8.405234197775522 val_acc : 32.02%\n",
      "Epoch [128/200] train_loss : 0.020075379222347454 train_acc : 99.37% val_loss : 7.225039541721344 val_acc : 30.79%\n",
      "Epoch [129/200] train_loss : 0.013972601014350262 train_acc : 99.42% val_loss : 8.115321238835653 val_acc : 31.53%\n",
      "Epoch [130/200] train_loss : 0.008805757574807133 train_acc : 99.47% val_loss : 7.510446488857269 val_acc : 31.53%\n",
      "Epoch [131/200] train_loss : 0.026991744277104428 train_acc : 99.16% val_loss : 7.313388268152873 val_acc : 27.34%\n",
      "Epoch [132/200] train_loss : 0.043437402628632396 train_acc : 98.61% val_loss : 8.247600754102072 val_acc : 28.08%\n",
      "Epoch [133/200] train_loss : 0.13382149334909155 train_acc : 96.51% val_loss : 9.05574345588684 val_acc : 25.12%\n",
      "Epoch [134/200] train_loss : 0.17544834606489781 train_acc : 95.62% val_loss : 8.334708213806152 val_acc : 29.80%\n",
      "Epoch [135/200] train_loss : 0.07496369859574947 train_acc : 97.82% val_loss : 7.342366576194763 val_acc : 31.28%\n",
      "Epoch [136/200] train_loss : 0.05081414597816917 train_acc : 98.20% val_loss : 8.123439709345499 val_acc : 32.76%\n",
      "Epoch [137/200] train_loss : 0.05433884761338212 train_acc : 98.08% val_loss : 7.489873131116231 val_acc : 28.57%\n",
      "Epoch [138/200] train_loss : 0.03929510544743814 train_acc : 98.71% val_loss : 8.696494181950888 val_acc : 29.80%\n",
      "Epoch [139/200] train_loss : 0.02954481593698295 train_acc : 98.94% val_loss : 8.546740810076395 val_acc : 31.03%\n",
      "Epoch [140/200] train_loss : 0.03004863756435265 train_acc : 99.01% val_loss : 8.020784457524618 val_acc : 31.03%\n",
      "Epoch [141/200] train_loss : 0.017377344672497675 train_acc : 99.22% val_loss : 8.642637292544046 val_acc : 28.82%\n",
      "Epoch [142/200] train_loss : 0.011113823131925129 train_acc : 99.44% val_loss : 8.535611470540365 val_acc : 32.02%\n",
      "Epoch [143/200] train_loss : 0.027065611361350175 train_acc : 98.99% val_loss : 7.96912403901418 val_acc : 30.30%\n",
      "Epoch [144/200] train_loss : 0.061748874501994934 train_acc : 98.18% val_loss : 8.696953773498535 val_acc : 27.59%\n",
      "Epoch [145/200] train_loss : 0.09185943402473817 train_acc : 97.24% val_loss : 9.698246280352274 val_acc : 28.08%\n",
      "Epoch [146/200] train_loss : 0.1150486489841421 train_acc : 96.74% val_loss : 7.924480239550273 val_acc : 28.57%\n",
      "Epoch [147/200] train_loss : 0.0800810784609147 train_acc : 97.82% val_loss : 7.738300720850627 val_acc : 32.76%\n",
      "Epoch [148/200] train_loss : 0.03356816044298632 train_acc : 98.68% val_loss : 8.381831725438436 val_acc : 33.00%\n",
      "Epoch [149/200] train_loss : 0.024981514446405003 train_acc : 98.94% val_loss : 7.972847104072571 val_acc : 33.25%\n",
      "model saved to /data/allen/hw4model/setting_b.pth\n",
      "Epoch [150/200] train_loss : 0.014063499166422104 train_acc : 99.32% val_loss : 7.886136412620544 val_acc : 35.71%\n",
      "Epoch [151/200] train_loss : 0.009722602027815027 train_acc : 99.44% val_loss : 8.109444816907247 val_acc : 34.24%\n",
      "Epoch [152/200] train_loss : 0.016600178471977912 train_acc : 99.27% val_loss : 7.318951964378357 val_acc : 32.27%\n",
      "Epoch [153/200] train_loss : 0.010820017366013158 train_acc : 99.27% val_loss : 7.773971875508626 val_acc : 33.25%\n",
      "Epoch [154/200] train_loss : 0.01655201943599589 train_acc : 99.14% val_loss : 8.453880429267883 val_acc : 33.99%\n",
      "Epoch [155/200] train_loss : 0.022710878715854487 train_acc : 99.16% val_loss : 8.239587585131327 val_acc : 30.54%\n",
      "Epoch [156/200] train_loss : 0.11832957736768866 train_acc : 97.09% val_loss : 8.157132625579834 val_acc : 25.86%\n",
      "Epoch [157/200] train_loss : 0.14655772762891753 train_acc : 96.28% val_loss : 7.660274982452393 val_acc : 29.31%\n",
      "Epoch [158/200] train_loss : 0.12300015389976068 train_acc : 96.41% val_loss : 8.991597612698873 val_acc : 26.35%\n",
      "Epoch [159/200] train_loss : 0.05536526892222066 train_acc : 97.98% val_loss : 8.465646465619406 val_acc : 30.79%\n",
      "Epoch [160/200] train_loss : 0.026364152630341524 train_acc : 98.84% val_loss : 9.105218092600504 val_acc : 30.30%\n",
      "Epoch [161/200] train_loss : 0.024933591418232943 train_acc : 98.99% val_loss : 9.083613077799479 val_acc : 32.27%\n",
      "Epoch [162/200] train_loss : 0.015023158948661545 train_acc : 99.37% val_loss : 10.00695820649465 val_acc : 31.28%\n",
      "Epoch [163/200] train_loss : 0.04252390912893688 train_acc : 98.56% val_loss : 9.16856861114502 val_acc : 31.03%\n",
      "Epoch [164/200] train_loss : 0.04635851925869668 train_acc : 98.51% val_loss : 8.798150579134623 val_acc : 31.03%\n",
      "Epoch [165/200] train_loss : 0.027530200725382238 train_acc : 98.73% val_loss : 9.229773918787638 val_acc : 31.53%\n",
      "Epoch [166/200] train_loss : 0.03218785107586941 train_acc : 98.71% val_loss : 9.337915301322937 val_acc : 31.28%\n",
      "Epoch [167/200] train_loss : 0.05817241205569643 train_acc : 97.95% val_loss : 9.371073762575785 val_acc : 27.83%\n",
      "Epoch [168/200] train_loss : 0.05131606500856101 train_acc : 98.38% val_loss : 9.11242683728536 val_acc : 31.03%\n",
      "Epoch [169/200] train_loss : 0.08214181267464844 train_acc : 97.72% val_loss : 9.139945069948832 val_acc : 25.12%\n",
      "Epoch [170/200] train_loss : 0.06709549868802293 train_acc : 98.10% val_loss : 8.276357571283976 val_acc : 30.05%\n",
      "Epoch [171/200] train_loss : 0.057277451136290965 train_acc : 98.25% val_loss : 9.498939871788025 val_acc : 31.77%\n",
      "Epoch [172/200] train_loss : 0.05986427661981559 train_acc : 98.18% val_loss : 8.404239694277445 val_acc : 30.54%\n",
      "Epoch [173/200] train_loss : 0.024642236513899685 train_acc : 99.04% val_loss : 8.743822813034058 val_acc : 32.02%\n",
      "Epoch [174/200] train_loss : 0.013402099360922046 train_acc : 99.29% val_loss : 8.158389568328857 val_acc : 32.76%\n",
      "Epoch [175/200] train_loss : 0.009007082689093728 train_acc : 99.44% val_loss : 8.079322497049967 val_acc : 31.53%\n",
      "Epoch [176/200] train_loss : 0.008849857520760809 train_acc : 99.52% val_loss : 8.215994040171305 val_acc : 32.76%\n",
      "Epoch [177/200] train_loss : 0.007886283003285754 train_acc : 99.44% val_loss : 8.140626470247904 val_acc : 33.25%\n",
      "Epoch [178/200] train_loss : 0.0076651411640569515 train_acc : 99.54% val_loss : 8.25617221991221 val_acc : 33.00%\n",
      "Epoch [179/200] train_loss : 0.007260793632760057 train_acc : 99.52% val_loss : 8.397230426470438 val_acc : 32.51%\n",
      "Epoch [180/200] train_loss : 0.007832854174915051 train_acc : 99.44% val_loss : 8.280772765477499 val_acc : 32.76%\n",
      "Epoch [181/200] train_loss : 0.008007410264089762 train_acc : 99.49% val_loss : 8.218610525131226 val_acc : 32.76%\n",
      "Epoch [182/200] train_loss : 0.00849992705216519 train_acc : 99.39% val_loss : 8.300676782925924 val_acc : 32.51%\n",
      "Epoch [183/200] train_loss : 0.007455681921272009 train_acc : 99.47% val_loss : 8.339160084724426 val_acc : 33.25%\n",
      "Epoch [184/200] train_loss : 0.008040024906152196 train_acc : 99.54% val_loss : 8.283215443293253 val_acc : 32.51%\n",
      "Epoch [185/200] train_loss : 0.008531966178386217 train_acc : 99.39% val_loss : 8.389063517252604 val_acc : 33.00%\n",
      "Epoch [186/200] train_loss : 0.007271808413479995 train_acc : 99.49% val_loss : 8.296874364217123 val_acc : 33.50%\n",
      "Epoch [187/200] train_loss : 0.0082517598891087 train_acc : 99.49% val_loss : 8.579213420550028 val_acc : 33.99%\n",
      "Epoch [188/200] train_loss : 0.007824013418149173 train_acc : 99.47% val_loss : 8.278961181640625 val_acc : 32.76%\n",
      "Epoch [189/200] train_loss : 0.0077434182187075505 train_acc : 99.42% val_loss : 8.398664514223734 val_acc : 33.00%\n",
      "Epoch [190/200] train_loss : 0.00798912334172413 train_acc : 99.52% val_loss : 8.364561835924784 val_acc : 33.25%\n",
      "Epoch [191/200] train_loss : 0.008501464146532424 train_acc : 99.42% val_loss : 8.363315065701803 val_acc : 32.51%\n",
      "Epoch [192/200] train_loss : 0.007675305524535578 train_acc : 99.60% val_loss : 8.12008531888326 val_acc : 34.73%\n",
      "Epoch [193/200] train_loss : 0.008262035810762685 train_acc : 99.47% val_loss : 8.002010703086853 val_acc : 34.48%\n",
      "Epoch [194/200] train_loss : 0.008557584788571063 train_acc : 99.47% val_loss : 8.394919594128927 val_acc : 34.98%\n",
      "Epoch [195/200] train_loss : 0.00794669092934245 train_acc : 99.57% val_loss : 8.27219295501709 val_acc : 35.22%\n",
      "Epoch [196/200] train_loss : 0.00885879389947211 train_acc : 99.52% val_loss : 8.220243215560913 val_acc : 33.99%\n",
      "Epoch [197/200] train_loss : 0.008615744005279395 train_acc : 99.54% val_loss : 8.107574820518494 val_acc : 33.74%\n",
      "Epoch [198/200] train_loss : 0.021096711862596738 train_acc : 99.22% val_loss : 9.158522725105286 val_acc : 22.91%\n",
      "Epoch [199/200] train_loss : 0.6916904312263175 train_acc : 84.54% val_loss : 7.063138127326965 val_acc : 27.83%\n",
      "Epoch [200/200] train_loss : 0.17440591690724913 train_acc : 95.22% val_loss : 7.299783567587535 val_acc : 31.77%\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for ep in range(config['epochs']):\n",
    "    model.train()\n",
    "    train_loss, train_acc, val_loss, val_acc = 0., 0., 0., 0.\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(config['device'])\n",
    "        logit = model(img).cpu()\n",
    "        loss = criterion(logit, label)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logit.argmax(-1) == label).float().sum()\n",
    "    train_loss /= idx\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(val_loader):\n",
    "            img = img.to(config['device'])\n",
    "            logit = model(img).cpu()\n",
    "            loss = criterion(logit, label)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logit.argmax(-1) == label).float().sum()\n",
    "        val_loss /= idx\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        save_checkpoint(config['save_pth'], model, opt)\n",
    "        best_acc = val_acc\n",
    "    print(f\"Epoch [{ep+1}/{config['epochs']}] train_loss : {train_loss} train_acc : {train_acc:.2%} val_loss : {val_loss} val_acc : {val_acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
