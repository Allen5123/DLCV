{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'train_pth':'/data/dlcv/hw4/office/train/',\n",
    "    'val_pth':'/data/dlcv/hw4/office/val/',\n",
    "    'train_csv_pth':'/data/dlcv/hw4/office/train.csv',\n",
    "    'val_csv_pth':'/data/dlcv/hw4/office/val.csv',\n",
    "    'save_pth':'/data/allen/hw4model/setting_d.pth',\n",
    "    'backbone_pth':'/data/dlcv/hw4/pretrain_model_SL.pt',\n",
    "    'bsz':32,\n",
    "    'lr':1.e-3,\n",
    "    'epochs':300,\n",
    "    'imgsz':128,\n",
    "    'numofclass':65\n",
    "}\n",
    "backbone_transform = transforms.Compose([\n",
    "    transforms.Resize((config['imgsz'], config['imgsz'])),\n",
    "    transforms.CenterCrop(config['imgsz']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225]))\n",
    "])\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.set_device(6)\n",
    "print('Device used :', config['device'])\n",
    "label2class = {'Alarm_Clock': 0, 'Backpack': 1, 'Batteries': 2, 'Bed': 3, 'Bike': 4, 'Bottle': 5, 'Bucket': 6, 'Calculator': 7, 'Calendar': 8, 'Candles': 9, 'Chair': 10, 'Clipboards': 11, 'Computer': 12, \n",
    "    'Couch': 13, 'Curtains': 14, 'Desk_Lamp': 15, 'Drill': 16, 'Eraser': 17, 'Exit_Sign': 18, 'Fan': 19, 'File_Cabinet': 20, 'Flipflops': 21, 'Flowers': 22, 'Folder': 23, 'Fork': 24, 'Glasses': 25,\n",
    "    'Hammer': 26, 'Helmet': 27, 'Kettle': 28, 'Keyboard': 29, 'Knives': 30, 'Lamp_Shade': 31, 'Laptop': 32, 'Marker': 33, 'Monitor': 34, 'Mop': 35, 'Mouse': 36, 'Mug': 37, 'Notebook': 38,\n",
    "    'Oven': 39, 'Pan': 40, 'Paper_Clip': 41, 'Pen': 42, 'Pencil': 43, 'Postit_Notes': 44, 'Printer': 45, 'Push_Pin': 46, 'Radio': 47, 'Refrigerator': 48, 'Ruler': 49, 'Scissors': 50, 'Screwdriver': 51,\n",
    "    'Shelf': 52, 'Sink': 53, 'Sneakers': 54, 'Soda': 55, 'Speaker': 56, 'Spoon': 57, 'TV': 58, 'Table': 59, 'Telephone': 60, 'ToothBrush': 61, 'Toys': 62, 'Trash_Can': 63, 'Webcam': 64}\n",
    "class2label = {0: 'Alarm_Clock', 1: 'Backpack', 2: 'Batteries', 3: 'Bed', 4: 'Bike', 5: 'Bottle', 6: 'Bucket', 7: 'Calculator', 8: 'Calendar', 9: 'Candles', 10: 'Chair', 11: 'Clipboards', 12: 'Computer', \n",
    "    13: 'Couch', 14: 'Curtains', 15: 'Desk_Lamp', 16: 'Drill', 17: 'Eraser', 18: 'Exit_Sign', 19: 'Fan', 20: 'File_Cabinet', 21: 'Flipflops', 22: 'Flowers', 23: 'Folder', 24: 'Fork', 25: 'Glasses', \n",
    "    26: 'Hammer', 27: 'Helmet', 28: 'Kettle', 29: 'Keyboard', 30: 'Knives', 31: 'Lamp_Shade', 32: 'Laptop', 33: 'Marker', 34: 'Monitor', 35: 'Mop', 36: 'Mouse', 37: 'Mug', 38: 'Notebook', \n",
    "    39: 'Oven', 40: 'Pan', 41: 'Paper_Clip', 42: 'Pen', 43: 'Pencil', 44: 'Postit_Notes', 45: 'Printer', 46: 'Push_Pin', 47: 'Radio', 48: 'Refrigerator', 49: 'Ruler', 50: 'Scissors', 51: 'Screwdriver', \n",
    "    52: 'Shelf', 53: 'Sink', 54: 'Sneakers', 55: 'Soda', 56: 'Speaker', 57: 'Spoon', 58: 'TV', 59: 'Table', 60: 'Telephone', 61: 'ToothBrush', 62: 'Toys', 63: 'Trash_Can', 64: 'Webcam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, device='cpu'):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    return checkpoint[\"model_state_dict\"], checkpoint[\"optimizer_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, datapath, csvpath, transform=None) -> None:\n",
    "        self.transform = transform\n",
    "        self.data = [] #(imgpath, imgname, #label)\n",
    "        if csvpath is not None:\n",
    "            if os.path.exists(csvpath):\n",
    "                df = pd.read_csv(csvpath)\n",
    "                self.data = [(os.path.join(datapath, name), name, label2class[label]) for name, label in zip(df['filename'], df['label'])]\n",
    "            else:\n",
    "                print(f\"Can't find {csvpath}\")\n",
    "                exit(-1)\n",
    "        else:\n",
    "            if os.path.exists(datapath):\n",
    "                paths = glob.glob(os.path.join(datapath, \"*\"))\n",
    "                for path in paths:\n",
    "                    imgname = os.path.split(path)[-1]\n",
    "                    self.data.append((path, imgname, None))\n",
    "            else:\n",
    "                print(f\"Can't open {datapath}\")\n",
    "                exit(-1)\n",
    "        self.len = len(self.data)\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgpath, imgname, label = self.data[index]\n",
    "        img = Image.open(imgpath)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label if label is not None else img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951\n",
      "406\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(DS(config['train_pth'], config['train_csv_pth'], transform=backbone_transform), batch_size=config['bsz'], shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(DS(config['val_pth'], config['val_csv_pth'], transform=backbone_transform), batch_size=config['bsz'], pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildLabelDict(train_csv):\n",
    "    label2class, class2label = {}, {}\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    labellist = sorted(list(dict.fromkeys([name for name in train_df['label']])))\n",
    "    label2class = {label : idx for (idx, label) in enumerate(labellist)}\n",
    "    class2label = {idx : label for (idx, label) in enumerate(labellist)}\n",
    "    print(label2class, class2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierD(nn.Module):\n",
    "    def __init__(self, backbone_pth) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=None)\n",
    "        self.backbone.load_state_dict(torch.load(backbone_pth, map_location=config['device']))\n",
    "        for param in (self.backbone).parameters():\n",
    "            param.requires_grad = False\n",
    "        self.classifier = nn.Linear(1000, config['numofclass'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.backbone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierD(config['backbone_pth']).to(config['device'])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to /data/allen/hw4model/setting_d.pth\n",
      "Epoch [1/300] train_loss : 2.3546960256933196 train_acc : 38.27% val_loss : 5.115717351436615 val_acc : 25.37%\n",
      "model saved to /data/allen/hw4model/setting_d.pth\n",
      "Epoch [2/300] train_loss : 2.3525830168065016 train_acc : 38.72% val_loss : 3.599956532319387 val_acc : 26.11%\n",
      "Epoch [3/300] train_loss : 2.340837972920115 train_acc : 39.51% val_loss : 4.286880930264791 val_acc : 25.37%\n",
      "Epoch [4/300] train_loss : 2.3422302550416654 train_acc : 38.72% val_loss : 4.1385283668835955 val_acc : 25.37%\n",
      "model saved to /data/allen/hw4model/setting_d.pth\n",
      "Epoch [5/300] train_loss : 2.312531308429997 train_acc : 39.66% val_loss : 3.592675725618998 val_acc : 26.85%\n",
      "Epoch [6/300] train_loss : 2.3156531806883773 train_acc : 39.18% val_loss : 3.485243101914724 val_acc : 26.11%\n",
      "Epoch [7/300] train_loss : 2.3217938052929514 train_acc : 38.72% val_loss : 3.7650034427642822 val_acc : 25.37%\n",
      "Epoch [8/300] train_loss : 2.315345358073227 train_acc : 38.75% val_loss : 4.46268634001414 val_acc : 26.35%\n",
      "Epoch [9/300] train_loss : 2.334660848950952 train_acc : 39.18% val_loss : 5.521986921628316 val_acc : 25.12%\n",
      "Epoch [10/300] train_loss : 2.332118870766182 train_acc : 38.80% val_loss : 3.596739113330841 val_acc : 25.37%\n",
      "Epoch [11/300] train_loss : 2.315849992317882 train_acc : 39.28% val_loss : 4.2589694658915205 val_acc : 25.12%\n",
      "Epoch [12/300] train_loss : 2.322184004434725 train_acc : 39.41% val_loss : 3.5905128916104636 val_acc : 26.35%\n",
      "Epoch [13/300] train_loss : 2.3123758449787046 train_acc : 39.79% val_loss : 3.835041324297587 val_acc : 24.88%\n",
      "Epoch [14/300] train_loss : 2.3227525939786338 train_acc : 38.85% val_loss : 3.996006270249685 val_acc : 25.62%\n",
      "Epoch [15/300] train_loss : 2.3174745464712623 train_acc : 40.45% val_loss : 5.170213282108307 val_acc : 22.91%\n",
      "Epoch [16/300] train_loss : 2.3349097812078834 train_acc : 38.17% val_loss : 3.996583342552185 val_acc : 26.11%\n",
      "Epoch [17/300] train_loss : 2.313037633895874 train_acc : 39.43% val_loss : 4.190623839696248 val_acc : 24.88%\n",
      "Epoch [18/300] train_loss : 2.300445802812654 train_acc : 39.21% val_loss : 4.2936073541641235 val_acc : 26.85%\n",
      "Epoch [19/300] train_loss : 2.3065060163901103 train_acc : 39.38% val_loss : 4.025652170181274 val_acc : 25.86%\n",
      "Epoch [20/300] train_loss : 2.297168903234528 train_acc : 39.96% val_loss : 3.9323041240374246 val_acc : 26.35%\n",
      "Epoch [21/300] train_loss : 2.3125042895960615 train_acc : 38.88% val_loss : 3.7767255306243896 val_acc : 26.60%\n",
      "Epoch [22/300] train_loss : 2.299535861829432 train_acc : 38.67% val_loss : 4.101332505544026 val_acc : 25.62%\n",
      "Epoch [23/300] train_loss : 2.31332543710383 train_acc : 39.08% val_loss : 3.876461088657379 val_acc : 25.86%\n",
      "Epoch [24/300] train_loss : 2.326486461530856 train_acc : 38.98% val_loss : 4.062697947025299 val_acc : 25.86%\n",
      "Epoch [25/300] train_loss : 2.306861701050425 train_acc : 40.04% val_loss : 4.26241934299469 val_acc : 25.62%\n",
      "Epoch [26/300] train_loss : 2.307221474686289 train_acc : 39.58% val_loss : 4.156478226184845 val_acc : 24.88%\n",
      "Epoch [27/300] train_loss : 2.306456760662358 train_acc : 40.60% val_loss : 4.083829979101817 val_acc : 26.85%\n",
      "Epoch [28/300] train_loss : 2.3088374670928085 train_acc : 39.56% val_loss : 3.9870732625325522 val_acc : 25.62%\n",
      "Epoch [29/300] train_loss : 2.3298298653548324 train_acc : 38.40% val_loss : 5.175534745057424 val_acc : 24.14%\n",
      "Epoch [30/300] train_loss : 2.3091181545722774 train_acc : 39.41% val_loss : 4.186184426148732 val_acc : 25.86%\n",
      "Epoch [31/300] train_loss : 2.3105077762913897 train_acc : 39.58% val_loss : 3.6574870149294534 val_acc : 25.62%\n",
      "Epoch [32/300] train_loss : 2.294201742342817 train_acc : 39.66% val_loss : 4.14060111840566 val_acc : 26.11%\n",
      "Epoch [33/300] train_loss : 2.278649724595915 train_acc : 40.77% val_loss : 4.3090605934460955 val_acc : 25.37%\n",
      "Epoch [34/300] train_loss : 2.2857307292581575 train_acc : 39.99% val_loss : 3.9773380160331726 val_acc : 26.85%\n",
      "model saved to /data/allen/hw4model/setting_d.pth\n",
      "Epoch [35/300] train_loss : 2.298993245372927 train_acc : 38.93% val_loss : 3.9555436968803406 val_acc : 27.34%\n",
      "Epoch [36/300] train_loss : 2.2743131058002874 train_acc : 41.23% val_loss : 3.9535826643308005 val_acc : 26.35%\n",
      "Epoch [37/300] train_loss : 2.305297411554228 train_acc : 38.95% val_loss : 4.121361295382182 val_acc : 26.35%\n",
      "Epoch [38/300] train_loss : 2.2879964074468226 train_acc : 39.58% val_loss : 4.058497627576192 val_acc : 24.14%\n",
      "Epoch [39/300] train_loss : 2.273931118530956 train_acc : 40.12% val_loss : 3.656591832637787 val_acc : 26.85%\n",
      "Epoch [40/300] train_loss : 2.286344334361999 train_acc : 40.09% val_loss : 4.062325676282247 val_acc : 26.11%\n",
      "model saved to /data/allen/hw4model/setting_d.pth\n",
      "Epoch [41/300] train_loss : 2.30021916366205 train_acc : 39.08% val_loss : 3.4861477414766946 val_acc : 28.33%\n",
      "Epoch [42/300] train_loss : 2.2774114909210827 train_acc : 40.22% val_loss : 3.7489726742108664 val_acc : 27.34%\n",
      "Epoch [43/300] train_loss : 2.272905080299067 train_acc : 39.53% val_loss : 3.633608102798462 val_acc : 27.09%\n",
      "Epoch [44/300] train_loss : 2.2939195293721144 train_acc : 40.39% val_loss : 4.113280177116394 val_acc : 24.88%\n",
      "Epoch [45/300] train_loss : 2.3033381380685944 train_acc : 39.38% val_loss : 3.6099207401275635 val_acc : 25.12%\n",
      "Epoch [46/300] train_loss : 2.2719792709117983 train_acc : 40.45% val_loss : 4.096899052460988 val_acc : 25.62%\n",
      "Epoch [47/300] train_loss : 2.2769631389679947 train_acc : 40.67% val_loss : 3.9054813782374063 val_acc : 25.86%\n",
      "Epoch [48/300] train_loss : 2.2916094510535885 train_acc : 39.89% val_loss : 4.906945923964183 val_acc : 24.14%\n",
      "Epoch [49/300] train_loss : 2.28373838827862 train_acc : 39.96% val_loss : 4.149929026762645 val_acc : 26.60%\n",
      "Epoch [50/300] train_loss : 2.2688496452036913 train_acc : 40.42% val_loss : 4.625821491082509 val_acc : 27.83%\n",
      "Epoch [51/300] train_loss : 2.282485886317928 train_acc : 39.94% val_loss : 3.566020747025808 val_acc : 26.60%\n",
      "Epoch [52/300] train_loss : 2.2735008049786574 train_acc : 40.80% val_loss : 3.9865803321202598 val_acc : 25.86%\n",
      "Epoch [53/300] train_loss : 2.264549668242292 train_acc : 40.42% val_loss : 4.615146855513255 val_acc : 25.37%\n",
      "Epoch [54/300] train_loss : 2.2885498777637636 train_acc : 39.56% val_loss : 4.336115181446075 val_acc : 24.38%\n",
      "Epoch [55/300] train_loss : 2.2864455071891228 train_acc : 40.09% val_loss : 4.157063106695811 val_acc : 25.62%\n",
      "Epoch [56/300] train_loss : 2.2690795815087914 train_acc : 40.47% val_loss : 4.7125703891118365 val_acc : 23.15%\n",
      "Epoch [57/300] train_loss : 2.2728739259688835 train_acc : 40.70% val_loss : 3.9718892176946006 val_acc : 26.85%\n",
      "Epoch [58/300] train_loss : 2.2809972230011857 train_acc : 41.23% val_loss : 4.573215742905934 val_acc : 25.37%\n",
      "Epoch [59/300] train_loss : 2.2786437999911424 train_acc : 40.42% val_loss : 4.653558194637299 val_acc : 26.85%\n",
      "Epoch [60/300] train_loss : 2.2762481303719 train_acc : 40.83% val_loss : 4.085328797499339 val_acc : 24.88%\n",
      "Epoch [61/300] train_loss : 2.270694995314125 train_acc : 41.20% val_loss : 4.2049373388290405 val_acc : 27.34%\n",
      "Epoch [62/300] train_loss : 2.25945253391576 train_acc : 40.47% val_loss : 4.173449218273163 val_acc : 26.35%\n",
      "Epoch [63/300] train_loss : 2.276822000984254 train_acc : 40.19% val_loss : 3.9692375461260476 val_acc : 28.08%\n",
      "Epoch [64/300] train_loss : 2.2781232023626807 train_acc : 40.42% val_loss : 4.522547364234924 val_acc : 25.62%\n",
      "Epoch [65/300] train_loss : 2.2696631865772776 train_acc : 40.60% val_loss : 4.206116735935211 val_acc : 26.60%\n",
      "Epoch [66/300] train_loss : 2.2537553698066772 train_acc : 41.10% val_loss : 3.9640761613845825 val_acc : 24.88%\n",
      "Epoch [67/300] train_loss : 2.25866943937007 train_acc : 40.75% val_loss : 4.295698801676433 val_acc : 27.09%\n",
      "Epoch [68/300] train_loss : 2.2813611524861033 train_acc : 39.69% val_loss : 4.321904540061951 val_acc : 27.09%\n",
      "Epoch [69/300] train_loss : 2.2531407645078207 train_acc : 40.27% val_loss : 3.994507352511088 val_acc : 25.86%\n",
      "Epoch [70/300] train_loss : 2.26110609469375 train_acc : 40.65% val_loss : 3.5362085898717246 val_acc : 27.09%\n",
      "Epoch [71/300] train_loss : 2.2534245078156636 train_acc : 41.64% val_loss : 3.6269226471583047 val_acc : 25.86%\n",
      "Epoch [72/300] train_loss : 2.2537410540309377 train_acc : 41.61% val_loss : 3.978077312310537 val_acc : 26.85%\n",
      "Epoch [73/300] train_loss : 2.239872748289651 train_acc : 41.71% val_loss : 3.6645570397377014 val_acc : 25.12%\n",
      "Epoch [74/300] train_loss : 2.2411811177323506 train_acc : 40.85% val_loss : 3.6127145886421204 val_acc : 25.37%\n",
      "Epoch [75/300] train_loss : 2.267068493656996 train_acc : 41.08% val_loss : 5.136622846126556 val_acc : 25.62%\n",
      "Epoch [76/300] train_loss : 2.256245934866308 train_acc : 40.77% val_loss : 4.14570168654124 val_acc : 26.60%\n",
      "Epoch [77/300] train_loss : 2.249348637534351 train_acc : 39.84% val_loss : 4.0044260422388716 val_acc : 27.09%\n",
      "Epoch [78/300] train_loss : 2.2684740351467596 train_acc : 41.15% val_loss : 3.7991528312365213 val_acc : 26.35%\n",
      "Epoch [79/300] train_loss : 2.2409973987718907 train_acc : 41.33% val_loss : 3.95339568456014 val_acc : 27.34%\n",
      "Epoch [80/300] train_loss : 2.2369134649028624 train_acc : 41.18% val_loss : 4.164504706859589 val_acc : 27.83%\n",
      "Epoch [81/300] train_loss : 2.2340806596647433 train_acc : 41.05% val_loss : 4.00215878089269 val_acc : 26.11%\n",
      "Epoch [82/300] train_loss : 2.2503770182772382 train_acc : 40.75% val_loss : 3.8238937060038247 val_acc : 26.60%\n",
      "Epoch [83/300] train_loss : 2.2246741385963875 train_acc : 42.09% val_loss : 3.91302881638209 val_acc : 25.37%\n",
      "Epoch [84/300] train_loss : 2.240875437007687 train_acc : 41.15% val_loss : 3.9850144584973655 val_acc : 26.35%\n",
      "Epoch [85/300] train_loss : 2.234991956532486 train_acc : 42.01% val_loss : 3.6196778813997903 val_acc : 25.62%\n",
      "Epoch [86/300] train_loss : 2.237765360653885 train_acc : 41.76% val_loss : 3.634027659893036 val_acc : 23.89%\n",
      "Epoch [87/300] train_loss : 2.224523778853378 train_acc : 41.56% val_loss : 3.990261654059092 val_acc : 25.12%\n",
      "Epoch [88/300] train_loss : 2.243397799933829 train_acc : 40.95% val_loss : 3.733655830224355 val_acc : 25.12%\n",
      "Epoch [89/300] train_loss : 2.2179148003337827 train_acc : 41.74% val_loss : 4.7101273735364275 val_acc : 24.88%\n",
      "Epoch [90/300] train_loss : 2.2556947518170363 train_acc : 40.29% val_loss : 4.067686319351196 val_acc : 25.86%\n",
      "Epoch [91/300] train_loss : 2.2240661256681613 train_acc : 40.83% val_loss : 4.25086110830307 val_acc : 26.60%\n",
      "Epoch [92/300] train_loss : 2.258685202133365 train_acc : 40.67% val_loss : 4.6840042273203535 val_acc : 24.88%\n",
      "Epoch [93/300] train_loss : 2.240457521221502 train_acc : 41.64% val_loss : 4.0810732046763105 val_acc : 25.86%\n",
      "Epoch [94/300] train_loss : 2.225115773154468 train_acc : 41.53% val_loss : 4.264186501502991 val_acc : 26.85%\n",
      "Epoch [95/300] train_loss : 2.2345401320031018 train_acc : 41.26% val_loss : 4.575565457344055 val_acc : 25.86%\n",
      "Epoch [96/300] train_loss : 2.249194730588091 train_acc : 40.85% val_loss : 4.056927998860677 val_acc : 26.11%\n",
      "Epoch [97/300] train_loss : 2.222068184759559 train_acc : 41.56% val_loss : 4.140124301115672 val_acc : 27.09%\n",
      "Epoch [98/300] train_loss : 2.2393122940528682 train_acc : 41.64% val_loss : 4.185203452905019 val_acc : 26.35%\n",
      "Epoch [99/300] train_loss : 2.224831503581225 train_acc : 40.95% val_loss : 3.9412577549616494 val_acc : 24.88%\n",
      "Epoch [100/300] train_loss : 2.22407478917905 train_acc : 42.14% val_loss : 4.071199536323547 val_acc : 27.59%\n",
      "Epoch [101/300] train_loss : 2.232968488359839 train_acc : 41.33% val_loss : 4.848614017168681 val_acc : 28.08%\n",
      "Epoch [102/300] train_loss : 2.2397160917762817 train_acc : 40.60% val_loss : 3.8728421926498413 val_acc : 26.35%\n",
      "Epoch [103/300] train_loss : 2.2254582798577904 train_acc : 42.12% val_loss : 3.8488770723342896 val_acc : 25.37%\n",
      "Epoch [104/300] train_loss : 2.2181986696351834 train_acc : 41.28% val_loss : 4.020461400349935 val_acc : 27.83%\n",
      "Epoch [105/300] train_loss : 2.2107951602315516 train_acc : 41.94% val_loss : 3.7223704059918723 val_acc : 26.35%\n",
      "Epoch [106/300] train_loss : 2.229247327742538 train_acc : 41.46% val_loss : 3.699812412261963 val_acc : 25.12%\n",
      "Epoch [107/300] train_loss : 2.2176038114036003 train_acc : 41.46% val_loss : 3.8799142837524414 val_acc : 26.60%\n",
      "Epoch [108/300] train_loss : 2.2190187122763656 train_acc : 41.23% val_loss : 3.9705068469047546 val_acc : 26.11%\n",
      "Epoch [109/300] train_loss : 2.231579122504568 train_acc : 40.88% val_loss : 3.96642013390859 val_acc : 27.34%\n",
      "Epoch [110/300] train_loss : 2.2046394086465604 train_acc : 41.41% val_loss : 3.4613386392593384 val_acc : 25.62%\n",
      "Epoch [111/300] train_loss : 2.214161919384468 train_acc : 41.56% val_loss : 4.583184520403544 val_acc : 25.12%\n",
      "Epoch [112/300] train_loss : 2.2137008546813717 train_acc : 42.19% val_loss : 3.8697845339775085 val_acc : 26.60%\n",
      "Epoch [113/300] train_loss : 2.203491277811004 train_acc : 42.01% val_loss : 4.088663121064504 val_acc : 28.08%\n",
      "Epoch [114/300] train_loss : 2.229242389764243 train_acc : 40.39% val_loss : 4.106978356838226 val_acc : 26.35%\n",
      "Epoch [115/300] train_loss : 2.212706926392346 train_acc : 42.29% val_loss : 4.30453234910965 val_acc : 28.08%\n",
      "Epoch [116/300] train_loss : 2.2172898984536893 train_acc : 41.36% val_loss : 3.7911521395047507 val_acc : 27.34%\n",
      "Epoch [117/300] train_loss : 2.192249984276004 train_acc : 42.09% val_loss : 4.477767785390218 val_acc : 25.86%\n",
      "Epoch [118/300] train_loss : 2.2091128380317997 train_acc : 41.94% val_loss : 4.359143455823262 val_acc : 26.60%\n",
      "Epoch [119/300] train_loss : 2.2188179037435267 train_acc : 41.76% val_loss : 3.7623625795046487 val_acc : 25.37%\n",
      "Epoch [120/300] train_loss : 2.2029951684843234 train_acc : 41.58% val_loss : 4.372454027334849 val_acc : 25.86%\n",
      "Epoch [121/300] train_loss : 2.193046852825134 train_acc : 41.91% val_loss : 3.9592703382174173 val_acc : 26.85%\n",
      "Epoch [122/300] train_loss : 2.219169942344107 train_acc : 43.05% val_loss : 4.575103422005971 val_acc : 27.59%\n",
      "Epoch [123/300] train_loss : 2.1997504311848464 train_acc : 41.96% val_loss : 4.465860307216644 val_acc : 27.34%\n",
      "Epoch [124/300] train_loss : 2.203511169286278 train_acc : 41.99% val_loss : 3.6435064474741616 val_acc : 28.08%\n",
      "Epoch [125/300] train_loss : 2.2020728045362765 train_acc : 42.98% val_loss : 4.794338186581929 val_acc : 27.09%\n",
      "Epoch [126/300] train_loss : 2.201635105823114 train_acc : 42.22% val_loss : 3.5257293780644736 val_acc : 26.11%\n",
      "Epoch [127/300] train_loss : 2.202595151536833 train_acc : 42.09% val_loss : 4.568657120068868 val_acc : 25.62%\n",
      "Epoch [128/300] train_loss : 2.211129545196285 train_acc : 42.42% val_loss : 3.8424625992774963 val_acc : 26.35%\n",
      "Epoch [129/300] train_loss : 2.195198021283964 train_acc : 42.52% val_loss : 3.5868186155954995 val_acc : 25.62%\n",
      "Epoch [130/300] train_loss : 2.2036423615323817 train_acc : 41.41% val_loss : 3.93221124013265 val_acc : 28.08%\n",
      "Epoch [131/300] train_loss : 2.202887564170651 train_acc : 42.01% val_loss : 4.344981332619985 val_acc : 27.34%\n",
      "Epoch [132/300] train_loss : 2.1979363895044095 train_acc : 41.84% val_loss : 4.384236494700114 val_acc : 27.59%\n",
      "Epoch [133/300] train_loss : 2.2043116141140944 train_acc : 42.75% val_loss : 4.811534861723582 val_acc : 25.62%\n",
      "Epoch [134/300] train_loss : 2.199694392157764 train_acc : 42.39% val_loss : 3.4857826431592307 val_acc : 25.62%\n",
      "Epoch [135/300] train_loss : 2.185771640723314 train_acc : 42.50% val_loss : 3.8241841395696006 val_acc : 26.11%\n",
      "Epoch [136/300] train_loss : 2.206581478196431 train_acc : 41.53% val_loss : 4.888749897480011 val_acc : 25.37%\n",
      "Epoch [137/300] train_loss : 2.180936919964426 train_acc : 41.66% val_loss : 3.857040067513784 val_acc : 26.11%\n",
      "Epoch [138/300] train_loss : 2.17386085424966 train_acc : 42.34% val_loss : 4.416430393854777 val_acc : 27.09%\n",
      "Epoch [139/300] train_loss : 2.191903218021238 train_acc : 42.62% val_loss : 3.8643802603085837 val_acc : 26.60%\n",
      "Epoch [140/300] train_loss : 2.174489517522052 train_acc : 43.13% val_loss : 4.934946238994598 val_acc : 24.63%\n",
      "Epoch [141/300] train_loss : 2.1849599776229236 train_acc : 41.94% val_loss : 3.8989908695220947 val_acc : 26.60%\n",
      "Epoch [142/300] train_loss : 2.1802362087296276 train_acc : 42.01% val_loss : 4.538073897361755 val_acc : 25.12%\n",
      "Epoch [143/300] train_loss : 2.1989653430333953 train_acc : 42.82% val_loss : 3.7979862491289773 val_acc : 25.62%\n",
      "Epoch [144/300] train_loss : 2.187974970515181 train_acc : 42.07% val_loss : 5.185763557751973 val_acc : 24.88%\n",
      "Epoch [145/300] train_loss : 2.2040167203763636 train_acc : 42.50% val_loss : 3.8978968262672424 val_acc : 25.37%\n",
      "Epoch [146/300] train_loss : 2.1736956679724098 train_acc : 42.01% val_loss : 4.294123073418935 val_acc : 25.62%\n",
      "Epoch [147/300] train_loss : 2.187728072569622 train_acc : 42.50% val_loss : 4.612644255161285 val_acc : 25.62%\n",
      "Epoch [148/300] train_loss : 2.1864063749468423 train_acc : 43.46% val_loss : 4.014088431994121 val_acc : 25.37%\n",
      "Epoch [149/300] train_loss : 2.1715450635770472 train_acc : 43.36% val_loss : 3.8978530367215476 val_acc : 28.08%\n",
      "Epoch [150/300] train_loss : 2.167951868801582 train_acc : 43.15% val_loss : 4.351143896579742 val_acc : 26.60%\n",
      "Epoch [151/300] train_loss : 2.172362135677803 train_acc : 42.19% val_loss : 3.5791086157162986 val_acc : 26.11%\n",
      "Epoch [152/300] train_loss : 2.1810967166249347 train_acc : 42.12% val_loss : 3.8671235839525857 val_acc : 25.86%\n",
      "Epoch [153/300] train_loss : 2.181163402107673 train_acc : 42.65% val_loss : 4.077339609464009 val_acc : 24.63%\n",
      "Epoch [154/300] train_loss : 2.173957352715779 train_acc : 42.72% val_loss : 4.418557186921437 val_acc : 26.60%\n",
      "Epoch [155/300] train_loss : 2.1653546618252264 train_acc : 43.36% val_loss : 4.576078494389852 val_acc : 25.37%\n",
      "Epoch [156/300] train_loss : 2.2129032892909475 train_acc : 42.60% val_loss : 4.324295620123546 val_acc : 26.11%\n",
      "Epoch [157/300] train_loss : 2.2277399979955783 train_acc : 41.96% val_loss : 4.226279894510905 val_acc : 26.60%\n",
      "Epoch [158/300] train_loss : 2.17791986368536 train_acc : 43.53% val_loss : 3.6395973364512124 val_acc : 26.60%\n",
      "Epoch [159/300] train_loss : 2.175181813356353 train_acc : 43.15% val_loss : 3.684690316518148 val_acc : 26.60%\n",
      "Epoch [160/300] train_loss : 2.1493900025763164 train_acc : 43.38% val_loss : 3.6205829779307046 val_acc : 27.59%\n",
      "Epoch [161/300] train_loss : 2.1647603599036613 train_acc : 43.38% val_loss : 4.161381522814433 val_acc : 26.60%\n",
      "Epoch [162/300] train_loss : 2.166743772785838 train_acc : 42.42% val_loss : 4.003119468688965 val_acc : 26.60%\n",
      "Epoch [163/300] train_loss : 2.171696869338431 train_acc : 43.05% val_loss : 5.072279353936513 val_acc : 26.35%\n",
      "Epoch [164/300] train_loss : 2.1670313957260876 train_acc : 42.65% val_loss : 3.8475059270858765 val_acc : 26.35%\n",
      "Epoch [165/300] train_loss : 2.1679546803962895 train_acc : 42.57% val_loss : 3.7313152551651 val_acc : 25.37%\n",
      "Epoch [166/300] train_loss : 2.170190207357329 train_acc : 43.48% val_loss : 4.254082500934601 val_acc : 27.09%\n",
      "Epoch [167/300] train_loss : 2.172446199548923 train_acc : 42.17% val_loss : 4.4337069392204285 val_acc : 27.09%\n",
      "Epoch [168/300] train_loss : 2.1697457437592793 train_acc : 42.93% val_loss : 3.672092338403066 val_acc : 27.09%\n",
      "Epoch [169/300] train_loss : 2.1789856868061594 train_acc : 42.27% val_loss : 3.8845420479774475 val_acc : 25.62%\n",
      "Epoch [170/300] train_loss : 2.1700021028518677 train_acc : 42.80% val_loss : 3.783579170703888 val_acc : 26.11%\n",
      "Epoch [171/300] train_loss : 2.1628014624603398 train_acc : 43.20% val_loss : 4.36913800239563 val_acc : 25.62%\n",
      "Epoch [172/300] train_loss : 2.1552566115449117 train_acc : 42.98% val_loss : 4.6004864772160845 val_acc : 25.37%\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for ep in range(config['epochs']):\n",
    "    model.train()\n",
    "    train_loss, train_acc, val_loss, val_acc = 0., 0., 0., 0.\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(config['device'])\n",
    "        logit = model(img).cpu()\n",
    "        loss = criterion(logit, label)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logit.argmax(-1) == label).float().sum()\n",
    "    train_loss /= idx\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(val_loader):\n",
    "            img = img.to(config['device'])\n",
    "            logit = model(img).cpu()\n",
    "            loss = criterion(logit, label)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logit.argmax(-1) == label).float().sum()\n",
    "        val_loss /= idx\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        save_checkpoint(config['save_pth'], model, opt)\n",
    "        best_acc = val_acc\n",
    "    print(f\"Epoch [{ep+1}/{config['epochs']}] train_loss : {train_loss} train_acc : {train_acc:.2%} val_loss : {val_loss} val_acc : {val_acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
