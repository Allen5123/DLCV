{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen/anaconda3/envs/dlcv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from byol_pytorch import BYOL\n",
    "from torchvision import models\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'train_pth':'/data/dlcv/hw4/office/train/',\n",
    "    'val_pth':'/data/dlcv/hw4/office/val/',\n",
    "    'train_csv_pth':'/data/dlcv/hw4/office/train.csv',\n",
    "    'val_csv_pth':'/data/dlcv/hw4/office/val.csv',\n",
    "    'best_save_pth':'/data/allen/hw4model/setting_e.pth',\n",
    "    'last_save_pth':'/data/allen/hw4model/setting_e_last.pth',\n",
    "    'backbone_pth':'/data/allen/hw4model/longep/backbone2_last.pth',\n",
    "    'bsz':16,\n",
    "    'epochs':80,\n",
    "    'imgsz':128,\n",
    "    'numofclass':65\n",
    "}\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config['imgsz'], config['imgsz'])),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225]))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config['imgsz'], config['imgsz'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225]))\n",
    "])\n",
    "if config[\"device\"] == \"cuda\":\n",
    "    torch.cuda.set_device(7)\n",
    "print('Device used :', config['device'])\n",
    "label2class = {'Alarm_Clock': 0, 'Backpack': 1, 'Batteries': 2, 'Bed': 3, 'Bike': 4, 'Bottle': 5, 'Bucket': 6, 'Calculator': 7, 'Calendar': 8, 'Candles': 9, 'Chair': 10, 'Clipboards': 11, 'Computer': 12, \n",
    "    'Couch': 13, 'Curtains': 14, 'Desk_Lamp': 15, 'Drill': 16, 'Eraser': 17, 'Exit_Sign': 18, 'Fan': 19, 'File_Cabinet': 20, 'Flipflops': 21, 'Flowers': 22, 'Folder': 23, 'Fork': 24, 'Glasses': 25,\n",
    "    'Hammer': 26, 'Helmet': 27, 'Kettle': 28, 'Keyboard': 29, 'Knives': 30, 'Lamp_Shade': 31, 'Laptop': 32, 'Marker': 33, 'Monitor': 34, 'Mop': 35, 'Mouse': 36, 'Mug': 37, 'Notebook': 38,\n",
    "    'Oven': 39, 'Pan': 40, 'Paper_Clip': 41, 'Pen': 42, 'Pencil': 43, 'Postit_Notes': 44, 'Printer': 45, 'Push_Pin': 46, 'Radio': 47, 'Refrigerator': 48, 'Ruler': 49, 'Scissors': 50, 'Screwdriver': 51,\n",
    "    'Shelf': 52, 'Sink': 53, 'Sneakers': 54, 'Soda': 55, 'Speaker': 56, 'Spoon': 57, 'TV': 58, 'Table': 59, 'Telephone': 60, 'ToothBrush': 61, 'Toys': 62, 'Trash_Can': 63, 'Webcam': 64}\n",
    "class2label = {0: 'Alarm_Clock', 1: 'Backpack', 2: 'Batteries', 3: 'Bed', 4: 'Bike', 5: 'Bottle', 6: 'Bucket', 7: 'Calculator', 8: 'Calendar', 9: 'Candles', 10: 'Chair', 11: 'Clipboards', 12: 'Computer', \n",
    "    13: 'Couch', 14: 'Curtains', 15: 'Desk_Lamp', 16: 'Drill', 17: 'Eraser', 18: 'Exit_Sign', 19: 'Fan', 20: 'File_Cabinet', 21: 'Flipflops', 22: 'Flowers', 23: 'Folder', 24: 'Fork', 25: 'Glasses', \n",
    "    26: 'Hammer', 27: 'Helmet', 28: 'Kettle', 29: 'Keyboard', 30: 'Knives', 31: 'Lamp_Shade', 32: 'Laptop', 33: 'Marker', 34: 'Monitor', 35: 'Mop', 36: 'Mouse', 37: 'Mug', 38: 'Notebook', \n",
    "    39: 'Oven', 40: 'Pan', 41: 'Paper_Clip', 42: 'Pen', 43: 'Pencil', 44: 'Postit_Notes', 45: 'Printer', 46: 'Push_Pin', 47: 'Radio', 48: 'Refrigerator', 49: 'Ruler', 50: 'Scissors', 51: 'Screwdriver', \n",
    "    52: 'Shelf', 53: 'Sink', 54: 'Sneakers', 55: 'Soda', 56: 'Speaker', 57: 'Spoon', 58: 'TV', 59: 'Table', 60: 'Telephone', 61: 'ToothBrush', 62: 'Toys', 63: 'Trash_Can', 64: 'Webcam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer, scheduler, ep, best_loss):\n",
    "    state = {'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict' : optimizer.state_dict(),\n",
    "             'scheduler_state_dict':scheduler.state_dict(),\n",
    "             'last_ep':ep,\n",
    "             'best_loss':best_loss\n",
    "             }\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('checkpoint saved to {}'.format(checkpoint_path))\n",
    "\n",
    "def save_model_only(checkpoint_path, model):\n",
    "    state = {'model_state_dict': model.state_dict(),}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to {}'.format(checkpoint_path))\n",
    "\n",
    "def load_checkpoint(checkpoint_path, device='cpu'):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    return checkpoint[\"model_state_dict\"], checkpoint[\"optimizer_state_dict\"], checkpoint[\"scheduler_state_dict\"], checkpoint['last_ep'], checkpoint['best_loss']\n",
    "\n",
    "def load_model_only(checkpoint_path, device='cpu'):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    return checkpoint[\"model_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, datapath, csvpath, transform=None) -> None:\n",
    "        self.transform = transform\n",
    "        self.data = [] #(imgpath, imgname, #label)\n",
    "        if csvpath is not None:\n",
    "            if os.path.exists(csvpath):\n",
    "                df = pd.read_csv(csvpath)\n",
    "                self.data = [(os.path.join(datapath, name), name, label2class[label]) for name, label in zip(df['filename'], df['label'])]\n",
    "            else:\n",
    "                print(f\"Can't find {csvpath}\")\n",
    "                exit(-1)\n",
    "        else:\n",
    "            if os.path.exists(datapath):\n",
    "                paths = glob.glob(os.path.join(datapath, \"*\"))\n",
    "                for path in paths:\n",
    "                    imgname = os.path.split(path)[-1]\n",
    "                    self.data.append((path, imgname, None))\n",
    "            else:\n",
    "                print(f\"Can't open {datapath}\")\n",
    "                exit(-1)\n",
    "        self.len = len(self.data)\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgpath, imgname, label = self.data[index]\n",
    "        img = Image.open(imgpath)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label if label is not None else img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951\n",
      "406\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(DS(config['train_pth'], config['train_csv_pth'], transform=train_transform), batch_size=config['bsz'], shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(DS(config['val_pth'], config['val_csv_pth'], transform=val_transform), batch_size=config['bsz'], pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildLabelDict(train_csv):\n",
    "    label2class, class2label = {}, {}\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    labellist = sorted(list(dict.fromkeys([name for name in train_df['label']])))\n",
    "    label2class = {label : idx for (idx, label) in enumerate(labellist)}\n",
    "    class2label = {idx : label for (idx, label) in enumerate(labellist)}\n",
    "    print(label2class, class2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierC(nn.Module):\n",
    "    def __init__(self, backbonepth=None) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=None)\n",
    "        if backbonepth is not None:\n",
    "            self.backbone.load_state_dict(load_model_only(backbonepth, device=config['device']))\n",
    "            print(f'load backbone from {backbonepth}')\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "        for param in (self.backbone).parameters():\n",
    "            param.requires_grad = False\n",
    "        self.classifier = nn.Linear(2048, config['numofclass'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(1)\n",
    "        return self.classifier(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load backbone from /data/allen/hw4model/longep/backbone2_last.pth\n"
     ]
    }
   ],
   "source": [
    "model = ClassifierC(config['backbone_pth']).to(config['device'])\n",
    "opt = torch.optim.RAdam(model.parameters(), lr=1.e-3, weight_decay=1.5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=config['epochs'])\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [1/80] train_loss : 4.139132396961616 train_acc : 6.0997% val_loss : 4.186125993728638 val_acc : 11.5764%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [2/80] train_loss : 3.9853234824126327 train_acc : 11.2883% val_loss : 3.995730094909668 val_acc : 17.2414%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [3/80] train_loss : 3.8276389788805956 train_acc : 14.9329% val_loss : 3.8134273719787597 val_acc : 22.1675%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [4/80] train_loss : 3.670520966615134 train_acc : 18.9572% val_loss : 3.6421076393127443 val_acc : 21.4286%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [5/80] train_loss : 3.5418625100841368 train_acc : 19.7165% val_loss : 3.513983545303345 val_acc : 24.3842%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [6/80] train_loss : 3.428195327278075 train_acc : 21.7920% val_loss : 3.428190689086914 val_acc : 26.3547%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [7/80] train_loss : 3.3263494386905577 train_acc : 23.6143% val_loss : 3.3220918369293213 val_acc : 24.3842%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [8/80] train_loss : 3.251461242272602 train_acc : 24.1711% val_loss : 3.251011514663696 val_acc : 28.3251%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [9/80] train_loss : 3.184790082094146 train_acc : 26.0947% val_loss : 3.200451593399048 val_acc : 28.3251%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [10/80] train_loss : 3.1361152369801593 train_acc : 26.6515% val_loss : 3.159550132751465 val_acc : 28.8177%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [11/80] train_loss : 3.0973380280704035 train_acc : 27.2083% val_loss : 3.102916135787964 val_acc : 28.5714%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [12/80] train_loss : 3.055469686422891 train_acc : 27.7145% val_loss : 3.0827609872817994 val_acc : 28.3251%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [13/80] train_loss : 2.9949307063730752 train_acc : 28.3219% val_loss : 3.0540451288223265 val_acc : 28.0788%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [14/80] train_loss : 2.988507682715005 train_acc : 28.2966% val_loss : 3.05190616607666 val_acc : 29.0640%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [15/80] train_loss : 2.9419727189754084 train_acc : 30.1696% val_loss : 3.0104474449157714 val_acc : 30.0493%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [16/80] train_loss : 2.8925313959276773 train_acc : 29.7393% val_loss : 2.9987666320800783 val_acc : 29.5566%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [17/80] train_loss : 2.8863982437102775 train_acc : 30.5998% val_loss : 2.9786952686309816 val_acc : 30.5419%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [18/80] train_loss : 2.862056953151052 train_acc : 29.6887% val_loss : 2.9493453216552736 val_acc : 30.0493%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [19/80] train_loss : 2.8474076627715816 train_acc : 31.2832% val_loss : 2.941821603775024 val_acc : 31.2808%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [20/80] train_loss : 2.8184027410135037 train_acc : 31.3845% val_loss : 2.932491493225098 val_acc : 30.0493%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [21/80] train_loss : 2.808185661711344 train_acc : 31.5110% val_loss : 2.92076021194458 val_acc : 29.5566%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [22/80] train_loss : 2.777063973550874 train_acc : 31.8653% val_loss : 2.8906955480575562 val_acc : 30.7882%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [23/80] train_loss : 2.762039023686231 train_acc : 33.6877% val_loss : 2.891554660797119 val_acc : 30.7882%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [24/80] train_loss : 2.7567301271407585 train_acc : 32.5487% val_loss : 2.8753249263763427 val_acc : 30.7882%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [25/80] train_loss : 2.7276157421794363 train_acc : 33.5105% val_loss : 2.898907127380371 val_acc : 30.7882%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [26/80] train_loss : 2.7205353398633196 train_acc : 33.3080% val_loss : 2.876481366157532 val_acc : 31.5271%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [27/80] train_loss : 2.7048792577371366 train_acc : 33.8902% val_loss : 2.8695558881759644 val_acc : 31.7734%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [28/80] train_loss : 2.700406505324976 train_acc : 34.3964% val_loss : 2.834134588241577 val_acc : 32.0197%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [29/80] train_loss : 2.68829647021565 train_acc : 34.0926% val_loss : 2.8498749208450316 val_acc : 32.7586%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [30/80] train_loss : 2.680405780067289 train_acc : 34.2698% val_loss : 2.837969408035278 val_acc : 30.7882%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [31/80] train_loss : 2.676530121787777 train_acc : 33.9155% val_loss : 2.8230342721939086 val_acc : 32.2660%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [32/80] train_loss : 2.6560394381119954 train_acc : 33.8902% val_loss : 2.8426595735549927 val_acc : 30.2956%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [33/80] train_loss : 2.6458805818867877 train_acc : 34.6241% val_loss : 2.8397594451904298 val_acc : 30.2956%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [34/80] train_loss : 2.6480369868317273 train_acc : 34.4470% val_loss : 2.8383753156661986 val_acc : 32.2660%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [35/80] train_loss : 2.624526082015619 train_acc : 34.6241% val_loss : 2.83969783782959 val_acc : 32.0197%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [36/80] train_loss : 2.6207132320093915 train_acc : 35.1557% val_loss : 2.823802638053894 val_acc : 32.7586%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [37/80] train_loss : 2.607809988463797 train_acc : 34.9532% val_loss : 2.7929208087921142 val_acc : 32.5123%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [38/80] train_loss : 2.6091284596823097 train_acc : 34.7507% val_loss : 2.782608232498169 val_acc : 31.2808%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [39/80] train_loss : 2.594674161779202 train_acc : 36.0415% val_loss : 2.790720052719116 val_acc : 30.7882%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [40/80] train_loss : 2.57367260620846 train_acc : 36.6236% val_loss : 2.76454535484314 val_acc : 32.5123%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [41/80] train_loss : 2.5726729466663145 train_acc : 35.9403% val_loss : 2.771311058998108 val_acc : 33.9901%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [42/80] train_loss : 2.5795600695338674 train_acc : 35.8390% val_loss : 2.7724452304840086 val_acc : 32.5123%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [43/80] train_loss : 2.5736024268274384 train_acc : 35.7884% val_loss : 2.765089168548584 val_acc : 33.4975%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [44/80] train_loss : 2.5475315703609125 train_acc : 36.2693% val_loss : 2.7652843952178956 val_acc : 30.5419%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [45/80] train_loss : 2.5501567357923927 train_acc : 37.0539% val_loss : 2.7693615436553953 val_acc : 32.0197%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [46/80] train_loss : 2.5498066815903515 train_acc : 36.6489% val_loss : 2.7604758310317994 val_acc : 32.5123%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [47/80] train_loss : 2.542632298740914 train_acc : 36.2187% val_loss : 2.7517386150360106 val_acc : 32.0197%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [48/80] train_loss : 2.540630401149998 train_acc : 37.1805% val_loss : 2.7567607069015505 val_acc : 30.5419%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [49/80] train_loss : 2.5315436182952507 train_acc : 36.1681% val_loss : 2.7383317804336547 val_acc : 32.2660%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [50/80] train_loss : 2.5269402522381728 train_acc : 36.3452% val_loss : 2.779301266670227 val_acc : 34.4828%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [51/80] train_loss : 2.5171069183000703 train_acc : 36.8008% val_loss : 2.73076886177063 val_acc : 34.4828%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [52/80] train_loss : 2.5045827685332878 train_acc : 37.0033% val_loss : 2.7463856172561645 val_acc : 32.2660%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [53/80] train_loss : 2.5190151416189304 train_acc : 37.5348% val_loss : 2.717881875038147 val_acc : 33.0049%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [54/80] train_loss : 2.507509394874418 train_acc : 37.8891% val_loss : 2.692665867805481 val_acc : 33.7438%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [55/80] train_loss : 2.5078319500132307 train_acc : 38.2182% val_loss : 2.7135834312438964 val_acc : 33.4975%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [56/80] train_loss : 2.5146383337858245 train_acc : 37.1805% val_loss : 2.6978580856323244 val_acc : 32.5123%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [57/80] train_loss : 2.483439683429594 train_acc : 38.0916% val_loss : 2.707157573699951 val_acc : 34.7291%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [58/80] train_loss : 2.489738612155604 train_acc : 37.4589% val_loss : 2.6896867847442625 val_acc : 32.5123%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [59/80] train_loss : 2.476580899905383 train_acc : 37.7373% val_loss : 2.7087091541290285 val_acc : 33.2512%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [60/80] train_loss : 2.468847236013025 train_acc : 38.3194% val_loss : 2.7058347511291503 val_acc : 33.7438%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [61/80] train_loss : 2.4700396773291797 train_acc : 37.8132% val_loss : 2.7012932205200197 val_acc : 33.9901%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [62/80] train_loss : 2.4665590384142186 train_acc : 38.5472% val_loss : 2.710126576423645 val_acc : 33.7438%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [63/80] train_loss : 2.4512530909321173 train_acc : 38.8256% val_loss : 2.723746657371521 val_acc : 35.2217%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [64/80] train_loss : 2.4433917941116707 train_acc : 38.1929% val_loss : 2.739610958099365 val_acc : 34.2365%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [65/80] train_loss : 2.4629165593201554 train_acc : 38.1676% val_loss : 2.6907440423965454 val_acc : 34.4828%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [66/80] train_loss : 2.4574907804892314 train_acc : 38.3194% val_loss : 2.7019077348709106 val_acc : 34.2365%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [67/80] train_loss : 2.459035209523953 train_acc : 38.3700% val_loss : 2.730282301902771 val_acc : 32.5123%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [68/80] train_loss : 2.461359646262192 train_acc : 38.1929% val_loss : 2.6757109498977663 val_acc : 34.2365%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [69/80] train_loss : 2.4552980075037576 train_acc : 38.3447% val_loss : 2.6562027072906496 val_acc : 36.6995%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [70/80] train_loss : 2.4293277796691024 train_acc : 39.6355% val_loss : 2.6435964250564576 val_acc : 37.1921%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [71/80] train_loss : 2.453907276556744 train_acc : 38.1929% val_loss : 2.699315991401672 val_acc : 34.9754%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [72/80] train_loss : 2.422652529991739 train_acc : 39.2053% val_loss : 2.6641944742202757 val_acc : 34.7291%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [73/80] train_loss : 2.4321555558258927 train_acc : 38.8256% val_loss : 2.667330026626587 val_acc : 35.4680%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [74/80] train_loss : 2.4100318575293067 train_acc : 39.5849% val_loss : 2.669377498626709 val_acc : 33.9901%\n",
      "model saved to /data/allen/hw4model/setting_e.pth\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [75/80] train_loss : 2.440374576463932 train_acc : 39.1546% val_loss : 2.6619426250457763 val_acc : 37.6847%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [76/80] train_loss : 2.4352617443092472 train_acc : 38.5219% val_loss : 2.6593456649780274 val_acc : 35.2217%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [77/80] train_loss : 2.418484202729977 train_acc : 39.8127% val_loss : 2.6722530937194824 val_acc : 35.2217%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [78/80] train_loss : 2.423653919037765 train_acc : 39.6102% val_loss : 2.6762193202972413 val_acc : 35.2217%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [79/80] train_loss : 2.40501215884356 train_acc : 39.8886% val_loss : 2.6533027935028075 val_acc : 35.4680%\n",
      "checkpoint saved to /data/allen/hw4model/setting_e_last.pth\n",
      "Epoch [80/80] train_loss : 2.4177712202072144 train_acc : 39.4584% val_loss : 2.6995610332489015 val_acc : 33.7438%\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for ep in range(config['epochs']):\n",
    "    model.train()\n",
    "    train_loss, train_acc, val_loss, val_acc = 0., 0., 0., 0.\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(config['device'])\n",
    "        logit = model(img).cpu()\n",
    "        loss = criterion(logit, label)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logit.argmax(-1) == label).float().sum()\n",
    "    train_loss /= idx\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(val_loader):\n",
    "            img = img.to(config['device'])\n",
    "            logit = model(img).cpu()\n",
    "            loss = criterion(logit, label)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logit.argmax(-1) == label).float().sum()\n",
    "        val_loss /= idx\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        save_model_only(config['best_save_pth'], model)\n",
    "        best_acc = val_acc\n",
    "    save_checkpoint(config['last_save_pth'], model, opt, scheduler, ep, best_acc)\n",
    "    print(f\"Epoch [{ep+1}/{config['epochs']}] train_loss : {train_loss} train_acc : {train_acc:.4%} val_loss : {val_loss} val_acc : {val_acc:.4%}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = load_model_only(config['best_save_pth'], config['device'])\n",
    "maxep = 100\n",
    "model = ClassifierC().to(config['device'])\n",
    "model.load_state_dict(model_state)\n",
    "opt = torch.optim.RAdam(model.parameters(), lr=4.e-5, weight_decay=5.e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=maxep)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "best_acc = 0.408867\n",
    "for ep in range(maxep):\n",
    "    model.train()\n",
    "    train_loss, train_acc, val_loss, val_acc = 0., 0., 0., 0.\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(config['device'])\n",
    "        logit = model(img).cpu()\n",
    "        loss = criterion(logit, label)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logit.argmax(-1) == label).float().sum()\n",
    "    scheduler.step()\n",
    "    train_loss /= idx\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(val_loader):\n",
    "            img = img.to(config['device'])\n",
    "            logit = model(img).cpu()\n",
    "            loss = criterion(logit, label)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logit.argmax(-1) == label).float().sum()\n",
    "        val_loss /= idx\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        save_model_only(config['best_save_pth'], model)\n",
    "        best_acc = val_acc\n",
    "    save_checkpoint(config['last_save_pth'], model, opt, scheduler, ep, best_acc)\n",
    "    print(f\"Epoch [{ep+1}/{maxep}] train_loss : {train_loss:.6f} train_acc : {train_acc:.6%} val_loss : {val_loss:.6f} val_acc : {val_acc:.6%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dlcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b129b87ef853288e118a1f4c2954e4d8b1d47adc530c957c0432333233c73696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
